# GitHub Actions CI/CD Pipeline - Friday 2.0
# Generated by BMad TEA Agent - Test Architect Module
# Optimized for: Python/pytest, Parallel Sharding, Burn-In Loop, Quality Gates

name: Test Pipeline

on:
  push:
    branches: [master, develop]
  pull_request:
    branches: [master, develop]
  schedule:
    # Weekly burn-in on Sundays at 2 AM UTC
    - cron: "0 2 * * 0"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Stage 1: Lint - Code Quality Gates
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  lint:
    name: Lint & Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install black isort flake8 mypy sqlfluff

      - name: Run black (formatting check)
        run: |
          echo "::group::Black - Code Formatting"
          black --check --line-length 100 agents/ services/ bot/ scripts/ || {
            echo "::error::Black formatting failed. Run 'black agents/ services/ bot/ scripts/' to fix."
            exit 1
          }
          echo "::endgroup::"

      - name: Run isort (import sorting check)
        run: |
          echo "::group::Isort - Import Sorting"
          isort --check-only --profile black agents/ services/ bot/ scripts/ || {
            echo "::error::Isort check failed. Run 'isort agents/ services/ bot/ scripts/' to fix."
            exit 1
          }
          echo "::endgroup::"

      - name: Run flake8 (linting)
        run: |
          echo "::group::Flake8 - Linting"
          flake8 agents/ services/ bot/ scripts/ || {
            echo "::error::Flake8 linting failed."
            exit 1
          }
          echo "::endgroup::"

      - name: Run mypy (type checking)
        run: |
          echo "::group::Mypy - Type Checking"
          mypy agents/ --strict --ignore-missing-imports || {
            echo "::warning::Mypy type checking found issues (non-blocking - migration progressive)"
          }
          echo "::endgroup::"

      - name: Run sqlfluff (SQL linting)
        run: |
          echo "::group::SQLFluff - SQL Linting"
          sqlfluff lint database/migrations/ --dialect postgres || {
            echo "::warning::SQLFluff found issues in migrations (non-blocking for legacy files)"
          }
          echo "::endgroup::"

      - name: âœ… Lint Summary
        if: success()
        run: |
          echo "::notice::âœ… All code quality checks passed!"

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Stage 2: Unit Tests - Parallel Sharding (4 shards)
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  test-unit:
    name: Unit Tests (Shard ${{ matrix.shard }}/4 - Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: lint

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        shard: [1, 2, 3, 4]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-py${{ matrix.python-version }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r agents/requirements-lock.txt
          pip install -e bot/
          pip install pytest pytest-asyncio pytest-cov pytest-xdist pytest-split

      - name: Run unit tests (shard ${{ matrix.shard }}/4)
        run: |
          echo "::group::Unit Tests - Shard ${{ matrix.shard }}/4"
          pytest tests/unit \
            -v \
            --tb=short \
            --cov=agents \
            --cov=bot \
            --cov-report=term-missing \
            --cov-report=xml \
            --junitxml=junit-unit-${{ matrix.shard }}.xml \
            --splits 4 \
            --group ${{ matrix.shard }} || {
            echo "::error::Unit tests failed on shard ${{ matrix.shard }}"
            exit 1
          }
          echo "::endgroup::"

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit-py${{ matrix.python-version }}-shard${{ matrix.shard }}
          path: coverage.xml
          retention-days: 30

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-unit-py${{ matrix.python-version }}-shard${{ matrix.shard }}
          path: junit-unit-${{ matrix.shard }}.xml
          retention-days: 30

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Stage 3: Integration Tests - PostgreSQL + Redis
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  test-integration:
    name: Integration Tests (PostgreSQL + Redis)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: lint

    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: friday_test
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: friday_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7.4
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r agents/requirements-lock.txt
          pip install -e bot/
          pip install pytest pytest-asyncio

      - name: Install PostgreSQL client tools
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y postgresql-client

      - name: Wait for PostgreSQL
        run: |
          timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U friday_test; do sleep 1; done'
          echo "::notice::PostgreSQL is ready"

      - name: Wait for Redis
        run: |
          sudo apt-get install -y redis-tools
          timeout 30 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
          echo "::notice::Redis is ready"

      - name: Apply database migrations
        env:
          DATABASE_URL: postgresql://friday_test:test_password@localhost:5432/friday_test
        run: |
          echo "::group::Database Migrations"
          python scripts/apply_migrations.py --no-backup || {
            echo "::error::Migration application failed"
            exit 1
          }
          echo "::endgroup::"

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://friday_test:test_password@localhost:5432/friday_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          echo "::group::Integration Tests"
          pytest tests/integration \
            -m integration \
            -v \
            --tb=short \
            --junitxml=junit-integration.xml || {
            echo "::error::Integration tests failed"
            exit 1
          }
          echo "::endgroup::"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-integration
          path: junit-integration.xml
          retention-days: 30

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Stage 4: Burn-In Loop - Flaky Test Detection
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  burn-in:
    name: Burn-In (Flaky Detection)
    runs-on: ubuntu-latest
    timeout-minutes: 90
    needs: [test-unit, test-integration]
    # Only run burn-in on PRs to master or on schedule
    if: github.event_name == 'pull_request' || github.event_name == 'schedule'

    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_USER: friday_test
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: friday_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7.4
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-burnin-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r agents/requirements-lock.txt
          pip install -e bot/
          pip install pytest pytest-asyncio

      - name: Install PostgreSQL client tools
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y postgresql-client redis-tools

      - name: Wait for services
        run: |
          timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U friday_test; do sleep 1; done'
          timeout 30 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'

      - name: Apply database migrations
        env:
          DATABASE_URL: postgresql://friday_test:test_password@localhost:5432/friday_test
        run: python scripts/apply_migrations.py --no-backup

      - name: Run burn-in loop (10 iterations)
        env:
          DATABASE_URL: postgresql://friday_test:test_password@localhost:5432/friday_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          echo "ğŸ”¥ Starting burn-in loop - detecting flaky tests"
          FAILURES=0
          for i in {1..10}; do
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "ğŸ”¥ Burn-in iteration $i/10"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

            # Run all tests
            if ! pytest tests/unit tests/integration -v --tb=short; then
              FAILURES=$((FAILURES + 1))
              echo "::error::âŒ Iteration $i failed"
            else
              echo "::notice::âœ… Iteration $i passed"
            fi

            # Reset database for next iteration
            python scripts/apply_migrations.py --no-backup > /dev/null 2>&1
          done

          if [ $FAILURES -gt 0 ]; then
            echo "::error::ğŸ”¥ Burn-in detected $FAILURES failures out of 10 iterations"
            echo "::error::âš ï¸ Flaky tests present - review logs above"
            exit 1
          else
            echo "::notice::âœ… Burn-in complete - no flaky tests detected"
          fi

      - name: Upload burn-in failure logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: burn-in-failures
          path: |
            .pytest_cache/
          retention-days: 30

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Stage 5: Report - Aggregate Results & Quality Gate
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  report:
    name: Test Report & Quality Gate
    runs-on: ubuntu-latest
    needs: [lint, test-unit, test-integration, burn-in]
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Generate test summary
        run: |
          echo "# ğŸ§ª Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint | ${{ needs.lint.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.test-unit.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.test-integration.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Burn-In | ${{ needs.burn-in.result == 'success' && 'âœ… Passed' || needs.burn-in.result == 'skipped' && 'â­ï¸ Skipped' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.burn-in.result }}" == "failure" ]; then
            echo "## âš ï¸ Flaky Tests Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The burn-in loop detected flaky tests. Review the artifacts for details." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          echo "## ğŸ“Š Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit Test Shards**: 4 parallel shards" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Versions**: 3.11, 3.12" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Shards**: 8 (4 shards Ã— 2 Python versions)" >> $GITHUB_STEP_SUMMARY
          echo "- **Burn-In Iterations**: 10" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Quality Gate - Enforce Success
        run: |
          LINT_STATUS="${{ needs.lint.result }}"
          UNIT_STATUS="${{ needs.test-unit.result }}"
          INTEGRATION_STATUS="${{ needs.test-integration.result }}"

          if [ "$LINT_STATUS" != "success" ]; then
            echo "::error::âŒ Quality Gate FAILED: Lint stage did not pass"
            exit 1
          fi

          if [ "$UNIT_STATUS" != "success" ]; then
            echo "::error::âŒ Quality Gate FAILED: Unit tests did not pass"
            exit 1
          fi

          if [ "$INTEGRATION_STATUS" != "success" ]; then
            echo "::error::âŒ Quality Gate FAILED: Integration tests did not pass"
            exit 1
          fi

          echo "::notice::âœ… Quality Gate PASSED - All critical stages successful"

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Additional Job: Docker Restart Policy Validation
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  validate-restart-policy:
    name: Validate Docker Restart Policies
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: lint

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate docker-compose.yml
        run: |
          bash scripts/validate-docker-restart-policy.sh docker-compose.yml || {
            echo "::error::docker-compose.yml validation failed"
            exit 1
          }

      - name: Validate docker-compose.services.yml
        run: |
          bash scripts/validate-docker-restart-policy.sh docker-compose.services.yml || {
            echo "::error::docker-compose.services.yml validation failed"
            exit 1
          }

  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  # Additional Job: Build Validation
  # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  build-validation:
    name: Build Validation (Docker)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: lint

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker images
        run: |
          echo "::group::Docker Build"
          docker compose build --no-cache || {
            echo "::error::Docker build failed"
            exit 1
          }
          echo "::endgroup::"

      - name: Verify builds succeeded
        run: |
          docker compose config --services
          echo "::notice::âœ… All Docker images built successfully"
