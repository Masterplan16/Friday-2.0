# CLAUDE.md - Friday 2.0

Instructions pour Claude Code lors du d√©veloppement de Friday 2.0.

---

## üåç Langue de travail

**IMPORTANT : Tous les √©changes doivent se faire en fran√ßais.**

---

## üìö Source de v√©rit√© architecturale

**R√àGLE ABSOLUE : Le document [_docs/architecture-friday-2.0.md](_docs/architecture-friday-2.0.md) est la r√©f√©rence unique pour toutes d√©cisions architecturales.**

En cas de doute ou conflit, se r√©f√©rer aux Steps 1-8 du document d'architecture.

---

## üéØ Principes architecturaux (NON N√âGOCIABLES)

### 1. KISS Day 1 - Start Simple, Split When Pain

**Toujours partir simple, refactorer seulement si douleur r√©elle.**

| Principe | Application |
|----------|-------------|
| **Structure flat** | `agents/src/agents/` = 23 modules au m√™me niveau Day 1 |
| **Refactoring trigger** | Module >500 lignes OU 3+ modules partagent >100 lignes identiques OU tests impossibles √† maintenir |
| **Pattern** | Extract interface ‚Üí Create adapter ‚Üí Replace implementation |
| **JAMAIS** | Big bang refactoring, sur-organisation pr√©matur√©e |

**Exemple :**
```python
# ‚úÖ CORRECT Day 1 (flat)
agents/src/agents/email/agent.py          # 450 lignes OK

# ‚ùå INCORRECT Day 1 (sur-organisation pr√©matur√©e)
agents/src/agents/email/
  ‚îú‚îÄ‚îÄ agent.py
  ‚îú‚îÄ‚îÄ classifier.py
  ‚îî‚îÄ‚îÄ summarizer.py
```

---

### 2. √âvolutibilit√© by design - Pattern adaptateur

**Chaque composant externe DOIT avoir un adaptateur.**

| Adaptateur | Fichier | Rempla√ßable par |
|------------|---------|-----------------|
| LLM | `adapters/llm.py` | Mistral ‚Üí Gemini/Claude (1 fichier) |
| Vectorstore | `adapters/vectorstore.py` | Qdrant ‚Üí Milvus/pgvector |
| Memorystore | `adapters/memorystore.py` | PostgreSQL+Qdrant (Day 1) ‚Üí Graphiti/Neo4j (si maturit√© atteinte) |
| Filesync | `adapters/filesync.py` | Syncthing ‚Üí rsync/rclone |
| Email | `adapters/email.py` | EmailEngine ‚Üí IMAP direct |

**Factory pattern obligatoire :**
```python
def get_llm_adapter() -> LLMAdapter:
    provider = os.getenv("LLM_PROVIDER", "mistral")
    if provider == "mistral":
        return MistralAdapter(api_key=os.getenv("MISTRAL_API_KEY"))
    # Extensible : ajouter Gemini, Claude, etc.
    raise ValueError(f"Unknown LLM provider: {provider}")
```

---

### 3. Contraintes mat√©rielles - VPS-4 OVH 48 Go RAM

**Tous services lourds r√©sidents en simultan√©. Plus d'exclusion mutuelle.**

| Service lourd | RAM | Mode |
|---------------|-----|------|
| Ollama Nemo 12B | ~8 Go | R√©sident |
| Faster-Whisper | ~4 Go | R√©sident |
| Kokoro TTS | ~2 Go | R√©sident |
| Surya OCR | ~2 Go | R√©sident |
| **Total services lourds** | **~16 Go** | |
| **Socle permanent (corrig√©)** | **~6.5-8.5 Go** | Inclut PG, Redis, Qdrant, n8n, Presidio, EmailEngine, Caddy, OS (SANS Zep - ferm√© 2024) |
| **Marge disponible** | **~24-25.5 Go** | |

**Orchestrator simplifi√© (moniteur RAM, pas gestionnaire d'exclusions) :**
```python
# config/profiles.py
SERVICE_RAM_PROFILES: dict[str, ServiceProfile] = {
    "ollama-nemo": ServiceProfile(ram_gb=8),
    "faster-whisper": ServiceProfile(ram_gb=4),
    "kokoro-tts": ServiceProfile(ram_gb=2),
    "surya-ocr": ServiceProfile(ram_gb=2),
}
RAM_ALERT_THRESHOLD_PCT = 85  # Alerte si d√©passe
```

**Plan B (VPS-3, 24 Go, 15‚Ç¨ TTC) :** Si besoin de r√©duire le budget ‚Üí r√©active les exclusions mutuelles via `VPS_TIER` env var.

---

### 4. S√©curit√© RGPD - Pipeline Presidio OBLIGATOIRE

**R√àGLE CRITIQUE : Anonymisation AVANT tout appel LLM cloud.**

```python
# ‚ùå INTERDIT
response = await mistral_client.chat(messages=[{"role": "user", "content": text_with_pii}])

# ‚úÖ CORRECT
anonymized_text = await presidio_anonymize(text_with_pii)
response = await mistral_client.chat(messages=[{"role": "user", "content": anonymized_text}])
result = await presidio_deanonymize(response)
```

**Autres r√®gles s√©curit√© :**
- Tailscale = RIEN expos√© sur Internet public (SSH uniquement via Tailscale, 2FA obligatoire)
- age/SOPS pour secrets (JAMAIS de `.env` en clair dans git, JAMAIS de credentials en default dans le code)
- pgcrypto pour colonnes sensibles BDD (donn√©es m√©dicales, financi√®res)
- Ollama local VPS pour donn√©es ultra-sensibles (pas de sortie cloud)
- Redis ACL : moindre privil√®ge par service (voir addendum section 9.2)
- Mapping Presidio : √©ph√©m√®re en m√©moire uniquement, JAMAIS stock√© en clair (voir addendum section 9.1)

---

### 5. Observability & Trust Layer - OBLIGATOIRE

**R√àGLE CRITIQUE : Chaque action de module DOIT passer par le d√©corateur `@friday_action`.**

#### Trust Levels (3 niveaux)

| Niveau | Comportement | Exemples |
|--------|-------------|----------|
| `auto` | Ex√©cute + notifie apr√®s coup | Classification email, OCR, briefing |
| `propose` | Pr√©pare + attend validation Telegram (inline buttons) | Brouillon r√©ponse mail, classement financier |
| `blocked` | Analyse uniquement, jamais d'action | Donn√©es m√©dicales, investissement, modification contrat |

**Initialisation par risque :** Low risk ‚Üí `auto`, Medium ‚Üí `propose`, High ‚Üí `blocked`.

**Promotion/r√©trogradation :**
- **R√©trogradation auto** : `auto` ‚Üí `propose` si accuracy <90% sur 1 semaine (√©chantillon ‚â•10 actions)
- **Promotion manuelle** : `propose` ‚Üí `auto` si accuracy ‚â•95% sur 3 semaines + validation Antonio
- **Anti-oscillation** : Apr√®s r√©trogradation, minimum 2 semaines avant nouvelle promotion

Voir [addendum section 7](_docs/architecture-addendum-20260205.md) pour la d√©finition formelle compl√®te (formule, granularit√© par action, seuils minimaux).

#### Middleware `@friday_action`

```python
# agents/src/middleware/trust.py
@friday_action(module="email", action="classify", trust_default="propose")
async def classify_email(email: Email) -> ActionResult:
    # 1. Charge les correction_rules du module
    rules = await db.fetch(
        "SELECT conditions, output FROM core.correction_rules "
        "WHERE module='email' AND active=true"
    )
    # 2. Injecte les r√®gles dans le prompt
    prompt = f"Classe cet email. R√®gles prioritaires: {format_rules(rules)}..."
    response = await mistral.chat(prompt=prompt)
    # 3. Retourne ActionResult standardis√©
    return ActionResult(
        input_summary=f"Email de {email.sender}: {email.subject}",
        output_summary=f"‚Üí {response.category}",
        confidence=response.score,
        reasoning=f"Mots-cl√©s: {response.keywords}..."
    )
```

#### ActionResult (mod√®le Pydantic obligatoire)

```python
# agents/src/middleware/models.py
class ActionResult(BaseModel):
    input_summary: str       # Ce qui est entr√©
    output_summary: str      # Ce qui a √©t√© fait
    confidence: float        # 0.0-1.0, confidence MIN de tous les steps
    reasoning: str           # Pourquoi cette d√©cision
    payload: dict = {}       # Donn√©es techniques optionnelles
    steps: list[StepDetail] = []  # Sous-√©tapes d√©taill√©es
```

#### Feedback Loop (r√®gles explicites, PAS de RAG)

```python
# ~50 r√®gles max ‚Üí un SELECT suffit, inject√©es dans le prompt
# Cycle : correction Antonio ‚Üí d√©tection pattern (2 occurrences) ‚Üí
#   proposition de r√®gle ‚Üí validation Antonio ‚Üí r√®gle active
```

#### Tables SQL associ√©es

- `core.action_receipts` ‚Äî Re√ßus de chaque action (migration `011_trust_system.sql`)
- `core.correction_rules` ‚Äî R√®gles de correction explicites
- `core.trust_metrics` ‚Äî Accuracy hebdomadaire par module/action

#### Commandes Telegram Trust

| Commande | Usage |
|----------|-------|
| `/status` | Dashboard temps r√©el (services, derni√®res actions) |
| `/journal` | 20 derni√®res actions avec timestamps |
| `/receipt <id>` | D√©tail complet d'une action (-v pour steps) |
| `/confiance` | Tableau accuracy par module |
| `/stats` | M√©triques globales agr√©g√©es |

#### Strat√©gie de Notification - Telegram Topics (Story 1.6)

**Architecture** : Supergroup Telegram avec **5 topics sp√©cialis√©s** (d√©cision 2026-02-05)

| Topic | R√¥le | Contenu |
|-------|------|---------|
| üí¨ **Chat & Proactive** (DEFAULT) | Conversation bidirectionnelle | Commandes, questions, heartbeat, reminders |
| üì¨ **Email & Communications** | Notifications email | Classifications, PJ, emails urgents |
| ü§ñ **Actions & Validations** | Validations trust=propose | Inline buttons Approve/Reject |
| üö® **System & Alerts** | Sant√© syst√®me | RAM >85%, services down, errors |
| üìä **Metrics & Logs** | M√©triques non-critiques | Actions auto, stats, logs |

**Rationale** : √âviter le chaos informationnel (tout m√©lang√© dans un seul canal = illisible). Topics permettent filtrage granulaire via mute/unmute natif Telegram selon contexte utilisateur.

**Contr√¥le utilisateur** :
- Mode Normal : Tous topics actifs
- Mode Focus : Mute Email + Metrics, garde Actions + System
- Mode Deep Work : Mute tout sauf System
- Pas de quiet hours cod√©es (utiliser fonctionnalit√©s natives t√©l√©phone)

**Voir** : [Architecture addendum ¬ß11](_docs/architecture-addendum-20260205.md#11-strat√©gie-de-notification--telegram-topics-architecture) pour sp√©cification compl√®te (routing logic, configuration, impact stories).

---

## üóÇÔ∏è Standards techniques

### PostgreSQL - 3 schemas obligatoires

| Schema | Contenu | Usage |
|--------|---------|-------|
| `core` | Configuration, jobs, audit, utilisateurs | Socle syst√®me, jamais touch√© par pipelines |
| `ingestion` | Emails, documents, fichiers, m√©tadonn√©es | Zone d'entr√©e donn√©es brutes |
| `knowledge` | Entit√©s, relations, m√©tadonn√©es embeddings | Zone de sortie post-traitement IA |

**JAMAIS** de table dans `public` schema.

---

### Migrations SQL - Num√©rot√©es, pas d'ORM

| √âl√©ment | Standard |
|---------|----------|
| Format | `001_init_schemas.sql`, `002_core_tables.sql`, etc. |
| Outil | Script Python custom `scripts/apply_migrations.py` |
| ORM | **AUCUN** (asyncpg brut) |
| Rollback | Via backup pr√©-migration automatique |

**Rationale :** Syst√®me pipeline/agent, pas CRUD classique. Requ√™tes optimis√©es √† la main.

---

### Pydantic v2 - Validation partout

| Usage | Fichiers |
|-------|----------|
| Schemas API | `services/gateway/schemas/*.py` (FastAPI natif) |
| Schemas pipeline | `agents/src/models/*.py` |
| Config | `agents/src/config/settings.py` (BaseSettings) |

---

### Event-driven - Redis Streams + Pub/Sub

**Format √©v√©nements :** Dot notation

**Transport : Redis Streams (√©v√©nements critiques) vs Pub/Sub (informatifs)**

| √âv√©nement | Transport | Justification |
|-----------|-----------|---------------|
| `email.received` | **Redis Streams** | Critique - perte = email non trait√© |
| `document.processed` | **Redis Streams** | Critique - perte = document ignor√© |
| `pipeline.error` | **Redis Streams** | Critique - perte = erreur silencieuse |
| `service.down` | **Redis Streams** | Critique - perte = panne non d√©tect√©e |
| `trust.level.changed` | **Redis Streams** | Critique - perte = incoh√©rence trust |
| `action.corrected` | **Redis Streams** | Critique - perte = feedback perdu |
| `action.validated` | **Redis Streams** | Critique - perte = validation perdue |
| `agent.completed` | Redis Pub/Sub | Non critique - retry possible |
| `file.uploaded` | Redis Pub/Sub | Non critique - d√©tectable par scan |

**R√®gle** : Tout √©v√©nement dont la perte entra√Æne une action manqu√©e ou une incoh√©rence d'√©tat ‚Üí Redis Streams. √âv√©nements informatifs/retry-safe ‚Üí Redis Pub/Sub.

**Communication patterns :**
- **Sync** : REST (FastAPI) pour requ√™tes
- **Async critique** : Redis Streams pour √©v√©nements m√©tier (delivery garanti)
- **Async informatif** : Redis Pub/Sub pour logs/notifications (fire-and-forget)
- **HTTP interne** : Docker network pour services (qdrant, n8n, etc.)

---

### Error handling - Hi√©rarchie standardis√©e

```python
# config/exceptions/__init__.py
class FridayError(Exception):
    """Base exception Friday 2.0"""
    pass

class PipelineError(FridayError):
    """Erreurs pipeline ingestion/traitement"""
    pass

class AgentError(FridayError):
    """Erreurs agents IA"""
    pass

class InsufficientRAMError(FridayError):
    """RAM insuffisante pour service lourd"""
    pass

# Retry automatique
RETRYABLE_EXCEPTIONS = (ConnectionError, TimeoutError, RateLimitError)
```

---

### Logging - JSON structur√©

```python
# config/logging.py (structlog)
{
    "timestamp": "2026-02-02T14:30:00Z",
    "service": "email-agent",
    "level": "INFO",
    "message": "Email classifi√©",
    "context": {
        "email_id": "abc123",
        "category": "medical",
        "confidence": 0.95
    }
}
```

---

### Naming conventions

| √âl√©ment | Convention | Exemple |
|---------|-----------|---------|
| Migrations SQL | Num√©rot√©es 3 chiffres | `001_init_schemas.sql` |
| Events Redis | Dot notation | `email.received` |
| Pydantic schemas | PascalCase | `EmailMessage`, `DocumentMetadata` |
| Fonctions Python | snake_case | `anonymize_text()`, `classify_email()` |
| Constantes | UPPER_SNAKE_CASE | `SERVICE_RAM_PROFILES` |

---

## üß™ Tests - Standards obligatoires

### Tests critiques RGPD

**Presidio anonymization :**
```python
# tests/integration/test_anonymization_pipeline.py
# Dataset : tests/fixtures/pii_samples.json
@pytest.mark.integration
async def test_presidio_anonymizes_all_pii(pii_samples):
    for sample in pii_samples:
        anonymized = await anonymize_text(sample["input"])
        # V√©rifier entit√©s sensibles anonymis√©es
        for entity_type in sample["entities"]:
            assert f"[{entity_type}_" in anonymized
        # V√©rifier pas de fuite PII
        for sensitive_value in sample["sensitive_values"]:
            assert sensitive_value not in anonymized
```

### Tests orchestrator RAM (VPS-4 48 Go)

```python
# tests/unit/supervisor/test_orchestrator.py
@pytest.mark.asyncio
async def test_ram_monitor_alerts_on_threshold():
    monitor = RAMMonitor(total_ram_gb=48, alert_threshold_pct=85)
    # Simuler charge √©lev√©e (>85%)
    monitor.simulate_usage(used_gb=42)
    alerts = await monitor.check()
    assert alerts[0].level == "warning"
    assert "85%" in alerts[0].message

@pytest.mark.asyncio
async def test_all_heavy_services_fit_in_ram():
    monitor = RAMMonitor(total_ram_gb=48, alert_threshold_pct=85)
    # Tous services lourds r√©sidents simultan√©ment
    services = ["ollama-nemo", "faster-whisper", "kokoro-tts", "surya-ocr"]
    for svc in services:
        await monitor.register_service(svc)
    assert monitor.total_allocated_gb <= 48 * 0.85  # Sous le seuil d'alerte
```

### Tests Trust Layer

```python
# tests/unit/middleware/test_trust.py
@pytest.mark.asyncio
async def test_friday_action_auto_executes_and_logs():
    """Trust=auto : ex√©cute l'action + cr√©e un receipt"""
    result = await classify_email(mock_email)
    receipt = await db.fetchrow("SELECT * FROM core.action_receipts ORDER BY created_at DESC LIMIT 1")
    assert receipt["status"] == "auto"
    assert receipt["confidence"] > 0

@pytest.mark.asyncio
async def test_friday_action_propose_waits_validation():
    """Trust=propose : cr√©e receipt pending + envoie inline buttons Telegram"""
    result = await draft_email_reply(mock_email)
    receipt = await db.fetchrow("SELECT * FROM core.action_receipts ORDER BY created_at DESC LIMIT 1")
    assert receipt["status"] == "pending"
    assert receipt["trust_level"] == "propose"

@pytest.mark.asyncio
async def test_auto_retrogradation_below_90pct():
    """Si accuracy < 90% sur 1 semaine ‚Üí r√©trograde auto ‚Üí propose"""
    # Simuler 10 actions dont 2 corrig√©es (80%)
    await simulate_corrections(module="email", action="classify", total=10, corrected=2)
    await run_nightly_metrics()
    new_level = await get_trust_level("email", "classify")
    assert new_level == "propose"
```

### Tests agents

**JAMAIS d'appels LLM r√©els en tests unitaires - Toujours mocker.**

```python
# ‚úÖ CORRECT
@patch("agents.tools.apis.mistral.MistralClient")
async def test_email_classifier(mock_mistral):
    mock_mistral.return_value.chat.return_value = "medical"
    # ...

# ‚ùå INCORRECT
async def test_email_classifier():
    # Appel r√©el √† Mistral API = co√ªteux + instable
```

---

## üö´ Anti-patterns (INTERDITS)

| Anti-pattern | Raison | Alternative |
|--------------|--------|-------------|
| **ORM (SQLAlchemy/Tortoise)** | Syst√®me pipeline, pas CRUD | asyncpg brut + SQL optimis√© |
| **Celery** | Redondant avec n8n + FastAPI | n8n (workflows longs) + BackgroundTasks (courts) |
| **Prometheus Day 1** | 400 Mo RAM, overkill m√™me sur VPS-4 48 Go | `scripts/monitor-ram.sh` (cron + Telegram) |
| **GraphQL** | Over-engineering utilisateur unique | REST + Pydantic suffit |
| **Structure 3 niveaux Day 1** | Sur-organisation pr√©matur√©e | Flat structure, refactor si douleur |
| **localStorage direct pour auth** | Token expir√©, pas de refresh | `api()` helper ou `getAuthHeaders()` |
| **Big bang refactoring** | Risque r√©gression massive | Refactoring incr√©mental si douleur r√©elle |

---

## üîß Commandes utiles

### Development

```bash
# Setup automatique environnement dev
./scripts/dev-setup.sh

# D√©marrer services core
docker compose up -d postgres redis qdrant

# Migrations
python scripts/apply_migrations.py

# Tests
pytest tests/unit -v                    # Tests unitaires
pytest tests/integration -v             # Tests int√©gration
pytest tests/e2e -v                     # Tests end-to-end
pytest --cov=agents --cov-report=html   # Coverage

# Linting
black agents/                           # Format code
isort agents/                           # Trier imports
mypy agents/ --strict                   # Type checking
flake8 agents/                          # Linting
```

### Production (VPS)

```bash
# D√©ploiement
./scripts/deploy.sh

# Monitoring RAM
./scripts/monitor-ram.sh                # Alerte si >85%

# Backup
./scripts/backup.sh                     # Backup BDD + volumes

# Logs
docker compose logs -f                  # Tous services
docker compose logs -f gateway          # Gateway uniquement
```

---

## üìã Checklist avant commit

**Pr√©-commit hooks automatiques :**
- [x] `black` (format code)
- [x] `isort` (trier imports)
- [x] `flake8` (linting)
- [x] `mypy --strict` (type checking)
- [x] `sqlfluff` (migrations SQL)

**Checklist manuelle :**
- [ ] Tests ajout√©s/mis √† jour pour nouveaux features
- [ ] Presidio anonymization si donn√©es sensibles touch√©es
- [ ] Adaptateurs utilis√©s pour composants externes (jamais d'import direct LLM/vectorstore)
- [ ] Configuration externalis√©e (pas de valeurs hardcod√©es)
- [ ] Logs structur√©s JSON (pas de print())
- [ ] Documentation mise √† jour si API publique modifi√©e
- [ ] `@friday_action` sur toute nouvelle action de module (trust level d√©fini)
- [ ] `ActionResult` retourn√© avec confidence et reasoning
- [ ] Trust level appropri√© au risque (auto/propose/blocked)

---

## üéØ First Implementation Priority

**Story 1 : Infrastructure de base** (partiellement impl√©ment√©e)

1. ‚úÖ Docker Compose (PostgreSQL 16, Redis 7, Qdrant, n8n 1.69.2, Caddy) ‚Äî **CR√â√â**
2. ‚úÖ Migrations SQL 001-010 (schemas core/ingestion/knowledge + tables, inclut `core.tasks` et `core.events`) ‚Äî **CR√â√âES**
3. üìã FastAPI Gateway + auth simple + OpenAPI
4. üìã Healthcheck endpoint (`GET /api/v1/health`)
5. üìã Tailscale configur√© (VPS hostname `friday-vps`)
6. üìã Tests end-to-end (sanity check tous services)

**Story 1.5 : Observability & Trust Layer (AVANT tout module)**

1. ‚úÖ Migration SQL `011_trust_system.sql` (tables receipts, rules, metrics) ‚Äî **CR√â√âE**
2. Middleware `@friday_action` + mod√®le `ActionResult`
3. Config trust levels par module (`agents/src/middleware/trust_levels.py`)
4. Bot Telegram : commandes `/status`, `/journal`, `/receipt`, `/confiance`, `/stats`
5. Validation inline buttons Telegram (approve/reject pour trust=propose)
6. Alerting listener Redis (`services/alerting/listener.py`)
7. Nightly metrics aggregation (`services/metrics/nightly.py`)
8. Tests unitaires + int√©gration trust middleware

**Story 2 : Module Email (premier module m√©tier)**

1. Agent Email (`agents/src/agents/email/agent.py`)
2. Classification emails (4 comptes IMAP)
3. Extraction PJ ‚Üí transit VPS ‚Üí Archiviste
4. Trust Level PROPOSE (validation humaine Day 1)
5. Tests unitaires + int√©gration

**Story 2.5 : Heartbeat Engine (proactivit√© native)** (~10h)

**D√©cision (2026-02-05)** : Impl√©menter Heartbeat natif Friday (vs OpenClaw complet ROI -86%)

1. ‚úÖ Spec technique compl√®te ‚Äî **CR√â√âE** ([agents/docs/heartbeat-engine-spec.md](agents/docs/heartbeat-engine-spec.md))
2. Class `FridayHeartbeat` (`agents/src/core/heartbeat.py`)
   - Interval configurable (default 30min)
   - LLM d√©cide dynamiquement quoi v√©rifier (contexte-aware)
   - Checks registration avec priorit√©s (high/medium/low)
   - Quiet hours (22h-8h)
3. `ContextProvider` (`agents/src/core/context.py`)
   - Heure, jour, weekend
   - Derni√®re activit√© Antonio
   - Prochain √©v√©nement calendrier
4. Checks Day 1 :
   - `check_urgent_emails` (high)
   - `check_financial_alerts` (medium)
   - `check_thesis_reminders` (low)
5. Configuration (`config/heartbeat.yaml`)
6. Int√©gration main (`agents/src/main.py`)
7. Monitoring endpoint (`/api/v1/heartbeat/status`)
8. Tests unitaires + int√©gration

**Rationale** : Antonio a besoin heartbeat proactif (critique Day 1) MAIS pas multi-chat ni skills OpenClaw ‚Üí Heartbeat natif = 100% b√©n√©fice recherch√© pour 14% co√ªt OpenClaw.

**Porte de sortie** : R√©√©valuation OpenClaw ao√ªt 2026 si besoins √©voluent (multi-chat, skills audit√©es identifi√©es).

**Story 3 : Module Finance + Archiviste**

1. Module Finance (classification transactions)
2. Module Archiviste (OCR, renommage, classement)
3. Int√©gration checks heartbeat (`check_financial_alerts`)

**D√©pendances critiques avant Story 2 :**
- PostgreSQL 16 op√©rationnel avec 3 schemas + migrations 001-012 appliqu√©es (inclut `core.tasks`, `core.events`, `ingestion.emails_legacy`)
- Redis 7 op√©rationnel (cache + Streams pour √©v√©nements critiques + Pub/Sub pour informatifs)
- FastAPI Gateway op√©rationnel avec `/api/v1/health`
- Tailscale mesh VPN configur√© (2FA obligatoire - **configuration manuelle** dans dashboard https://login.tailscale.com/admin/settings/auth)
- **`@friday_action` middleware op√©rationnel** (tout module en d√©pend)
- **Bot Telegram op√©rationnel** (canal unique de contr√¥le)
- **Presidio + spaCy-fr install√©s** (RGPD avant tout appel LLM cloud, mapping √©ph√©m√®re Redis TTL court)
- **Note** : ~~Apple Watch Ultra~~ hors scope Day 1 (pas d'API serveur, r√©√©valuation >12 mois)

**Fichiers Story 1 + 1.5 + 2.5 :**
- ‚úÖ `docker-compose.yml` + `docker-compose.services.yml` ‚Äî **CR√â√âS**
- ‚úÖ `database/migrations/001-012_*.sql` (Story 1 + 1.5) ‚Äî **CR√â√âES** (12 migrations inclut emails_legacy)
- üìã `scripts/apply_migrations.py` ‚Äî √Ä cr√©er (Story 1)
- ‚úÖ `scripts/migrate_emails.py` ‚Äî **CR√â√â** (corrig√© 110k mails)
- ‚úÖ `config/trust_levels.yaml` ‚Äî **CR√â√â**
- ‚úÖ `tests/fixtures/README.md` (plan datasets) ‚Äî **CR√â√â**
- ‚úÖ `.sops.yaml` ‚Äî **CR√â√â** (template secrets management)
- ‚úÖ `docs/DECISION_LOG.md` ‚Äî **CR√â√â** (historique d√©cisions + d√©cision OpenClaw 2026-02-05)
- ‚úÖ `docs/playwright-automation-spec.md` ‚Äî **CR√â√â** (spec Browser automation)
- ‚úÖ `agents/src/tools/anonymize.py` (Presidio integration) ‚Äî **CR√â√â** (Story 1.5.1)
- ‚úÖ `agents/src/middleware/models.py` (ActionResult) ‚Äî **CR√â√â** (Story 1.5.2)
- ‚úÖ `agents/src/middleware/trust.py` (@friday_action) ‚Äî **CR√â√â** (Story 1.5.2)
- ‚úÖ `services/alerting/` ‚Äî **CR√â√â** (listener Redis Streams + Telegram)
- ‚úÖ `services/metrics/` ‚Äî **CR√â√â** (nightly aggregation trust metrics)
- ‚úÖ `agents/docs/heartbeat-engine-spec.md` ‚Äî **CR√â√â** (spec Heartbeat Engine Story 2.5)
- ‚úÖ `_docs/architecture-addendum-20260205.md` ‚Äî **MIS √Ä JOUR** (section 4 : d√©cision OpenClaw + alternative Heartbeat)
- üìã `agents/src/core/heartbeat.py` ‚Äî √Ä cr√©er (Story 2.5)
- üìã `agents/src/core/context.py` ‚Äî √Ä cr√©er (Story 2.5)
- üìã `config/heartbeat.yaml` ‚Äî √Ä cr√©er (Story 2.5)

**D√©cision memorystore (2026-02-05)** : Zep a cess√© ses op√©rations en 2024. **Day 1** : D√©marrer avec `adapters/memorystore.py` pointant vers **PostgreSQL (knowledge.*) + Qdrant (embeddings)**. **R√©-√©valuation Graphiti** : 6 mois apr√®s Story 1 (~ao√ªt 2026) si v1.0 stable atteinte (crit√®res : >500 stars GitHub, doc API compl√®te, tests charge 100k+ entit√©s). Sinon ‚Üí Neo4j Community Edition. Voir [addendum section 10](_docs/architecture-addendum-20260205.md).

---

## üöÄ Workflows BMAD recommand√©s

| Workflow | Usage |
|----------|-------|
| `bmad:bmm:workflows:create-epics-and-stories` | Transformer architecture en stories impl√©mentables |
| `bmad:bmm:workflows:dev-story` | Impl√©menter une story (tasks/subtasks, tests, validation) |
| `bmad:bmm:workflows:code-review` | Review adversarial (trouver 3-10 probl√®mes minimum) |
| `bmad:bmm:workflows:quick-dev` | Dev flexible (tech-spec OU instructions directes) |
| `bmad:bmm:workflows:testarch-*` | Framework tests, ATDD, NFR assessment, CI/CD |

---

## üìû Notifications Windows (BurntToast)

**R√àGLE : Notifier l'utilisateur dans les cas suivants.**

```powershell
# T√¢che termin√©e
New-BurntToastNotification -Text "Claude", "T√¢che termin√©e ‚úì"

# Question / Besoin d'attention
New-BurntToastNotification -Text "Claude", "J'ai besoin de ton attention"

# Erreur bloquante
New-BurntToastNotification -Text "Claude", "Erreur - Action requise"

# Longue t√¢che en cours (>2min)
New-BurntToastNotification -Text "Claude", "Toujours en cours..."
```

---

## üìö Documentation de r√©f√©rence

### Documents principaux

- **Architecture compl√®te** : [_docs/architecture-friday-2.0.md](_docs/architecture-friday-2.0.md) (~2500 lignes)
  *Source de v√©rit√© unique pour toutes d√©cisions architecturales. Inclut : infrastructure, stack tech, s√©curit√© RGPD, graphe de connaissances, Trust Layer, clarifications techniques compl√®tes*

- **Analyse besoins** : [_docs/friday-2.0-analyse-besoins.md](_docs/friday-2.0-analyse-besoins.md)
  *Vision produit, 23 modules fonctionnels, sources de donn√©es, interconnexions, contraintes techniques (mise √† jour 2026-02-05)*

- **README** : [README.md](README.md)
  *Quick start, setup d√©veloppement, commandes utiles*

### Documents techniques additionnels

- **Workflows n8n** : [docs/n8n-workflows-spec.md](docs/n8n-workflows-spec.md)
  *Sp√©cifications compl√®tes des 3 workflows critiques Day 1 (Email Ingestion, Briefing Daily, Backup Daily). Includes nodes, triggers, variables, tests*

- **Strat√©gie tests IA** : [docs/testing-strategy-ai.md](docs/testing-strategy-ai.md)
  *Pyramide de tests (80% unit mocks, 15% integ datasets, 5% E2E). M√©triques qualit√©, datasets validation, tests critiques RGPD/RAM/Trust*

- **Roadmap impl√©mentation** : [docs/implementation-roadmap.md](docs/implementation-roadmap.md)
  *Stories d√©taill√©es (1-9+), s√©quence impl√©mentation, Acceptance Criteria, d√©pendances, dur√©es estim√©es*

- **Addendum architecture (2026-02-05)** : [_docs/architecture-addendum-20260205.md](_docs/architecture-addendum-20260205.md)
  *Clarifications techniques : Presidio benchmark, pattern detection algo, profils RAM, crit√®res OpenClaw, population graphe, trust retrogradation formelle (section 7), healthcheck complet (section 8), s√©curit√© compl√©ments (section 9), avertissement Zep (section 10)*

### Configuration & Scripts impl√©mentation

- **Trust levels config** : [config/trust_levels.yaml](config/trust_levels.yaml)
  *Configuration initiale trust levels pour les 23 modules (auto/propose/blocked par action)*

- **Script migration SQL** : [scripts/apply_migrations.py](scripts/apply_migrations.py)
  *Application migrations SQL avec tracking, backup automatique, rollback en cas d'erreur*

- **Script migration emails** : [scripts/migrate_emails.py](scripts/migrate_emails.py)
  *Migration 110k emails avec checkpointing, retry, resume, progress tracking*

- **Script monitoring RAM** : [scripts/monitor-ram.sh](scripts/monitor-ram.sh)
  *V√©rification usage RAM + alertes Telegram si >85% (cron-able)*

- **Script v√©rification env** : [scripts/verify_env.sh](scripts/verify_env.sh)
  *Validation variables d'environnement requises avant d√©marrage*

- **Script Redis Streams setup** : [scripts/setup-redis-streams.sh](scripts/setup-redis-streams.sh)
  *Cr√©ation consumer groups pour √©v√©nements critiques*

- **Test backup/restore** : [tests/e2e/test_backup_restore.sh](tests/e2e/test_backup_restore.sh)
  *Test E2E complet : backup PostgreSQL ‚Üí disaster simulation ‚Üí restore ‚Üí validation int√©grit√©*

- **Plan cr√©ation datasets** : [tests/fixtures/README.md](tests/fixtures/README.md)
  *Guide complet cr√©ation datasets tests IA (PII, Email Classification, Archiviste, Finance, Th√®se). Dur√©es, responsable, formats*

### Guides techniques additionnels

- **Secrets Management** : [docs/secrets-management.md](docs/secrets-management.md)
  *Guide complet age/SOPS : installation, chiffrement/d√©chiffrement .env, partage cl√©s, rotation*

- **Redis Streams Setup** : [docs/redis-streams-setup.md](docs/redis-streams-setup.md)
  *Configuration compl√®te Redis Streams : consumer groups, retry, recovery, monitoring*

- **Playwright Automation** : [docs/playwright-automation-spec.md](docs/playwright-automation-spec.md)
  *Sp√©cification automatisation web (Carrefour Drive, etc.) - Alternative fiable √† Browser-Use*

- **Decision Log** : [docs/DECISION_LOG.md](docs/DECISION_LOG.md)
  *Historique chronologique des d√©cisions architecturales majeures*

---

**Version** : 1.5.0 (2026-02-05)
**Status** : Architecture compl√®te + Observability & Trust Layer + Code Review Adversarial v2 (17 issues fixes) + Fichiers critiques cr√©√©s + Corrections VPS/emails/Apple Watch - **Pr√™t pour impl√©mentation Story 1**
