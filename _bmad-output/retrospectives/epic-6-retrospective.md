# R√©trospective Epic 6 : M√©moire √âternelle & Migration

**Date** : 2026-02-11
**Epic** : Epic 6 - M√©moire √âternelle & Migration (4 stories)
**Participants** : Mainteneur (Antonio), Alice (PO), Bob (SM), Charlie (Dev Lead)
**Dur√©e r√©trospective** : ~90 minutes

---

## üìã Contexte Epic 6

### Stories Compl√©t√©es (4/4)

| Story | Titre | Status | Tests | Budget |
|-------|-------|--------|-------|--------|
| **6.1** | Graphe de Connaissances PostgreSQL | ‚úÖ DONE | 40 unit tests | - |
| **6.2** | Embeddings pgvector & Voyage AI | ‚úÖ DONE | 36 tests (35 PASS + 1 skip) | $10-15/mois |
| **6.3** | Adaptateur MemoryStore | ‚úÖ DONE | 11 interface + 19 existing | - |
| **6.4** | Migration 110k Emails Historiques | ‚úÖ DONE | Phase 1-3 compl√®te | $332 r√©el |

**Total Epic 6** : 75+ tests, 100% stories compl√©t√©es, 0 bugs post-review

---

## üéØ Objectifs Epic 6 (rappel)

Epic 6 visait √† √©tablir le syst√®me de m√©moire persistante de Friday 2.0 :

1. **Knowledge Graph PostgreSQL** : Structure relationnelle pour entit√©s/relations/√©v√©nements (10 node types, 14 relation types)
2. **Embeddings vectoriels** : Recherche s√©mantique via pgvector (migration depuis Qdrant - D√©cision D19)
3. **Memorystore adapter** : Interface abstraite pour √©volutivit√© future (Graphiti/Neo4j)
4. **Migration 110k emails** : Population initiale du graphe depuis donn√©es historiques

---

## ‚úÖ What Went Well

### 1. **D√©cision D19 : pgvector Day 1** (2026-02-09)

**Contexte** : Architecture initiale pr√©voyait Qdrant pour embeddings vectoriels.

**D√©cision** : Remplacer Qdrant par **pgvector dans PostgreSQL** pour Day 1.

**Rationale** :
- Volume mod√©r√© (100k vecteurs, 1 utilisateur) ‚Üí pgvector suffit largement
- Simplification stack : -1 service Docker (Qdrant), -600 Mo RAM
- PostgreSQL 16 + pgvector = mature, performant pour notre √©chelle
- Latence acceptable : <100ms pour 100k vecteurs
- √âconomie co√ªts : pas de service vectoriel d√©di√©

**Impact** :
- Migration 008 modifi√©e : `knowledge.embeddings` avec `vector(1024)` + HNSW index
- `memorystore.py` r√©√©crit : `AsyncQdrantClient` ‚Üí `asyncpg` + pgvector
- `docker-compose.yml` : service Qdrant retir√©
- ~15 fichiers modifi√©s (migrations, code, tests, docs)

**Clause de r√©√©valuation** : Si >300k vecteurs OU latence >100ms ‚Üí r√©√©valuer Qdrant/Milvus

**R√©sultat** : ‚úÖ Stack simplifi√©e, socle RAM r√©duit (~6-8 Go), pgvector op√©rationnel

---

### 2. **Tests exhaustifs (75+ tests, 100% couverture critique)**

**Breakdown tests** :
- **Story 6.1** : 40 unit tests (graphe PostgreSQL, contraintes, relations)
- **Story 6.2** : 36 tests (embeddings, Voyage AI, pgvector queries)
- **Story 6.3** : 11 interface tests + 19 tests existing (factory pattern, ABC)
- **Story 6.4** : Tests int√©gration 3 phases (classification, graph, embeddings)

**Qualit√©** :
- ‚úÖ 0 bugs identifi√©s post-code review adversarial
- ‚úÖ 100% des modules critiques test√©s (graph, embeddings, adapter)
- ‚úÖ Tests isolation (mocks Voyage AI, pas d'appels r√©els API en unit tests)

**Pattern r√©utilisable** : Strat√©gie "80% unit mocks, 15% integration datasets, 5% E2E" valid√©e.

---

### 3. **Factory Pattern Memorystore (extensibilit√©)**

**Code Story 6.3** :
```python
# agents/src/adapters/memorystore.py
class MemoryStore(ABC):
    @abstractmethod
    async def store_entity(self, entity: Entity) -> str:
        pass

    @abstractmethod
    async def query_similar(self, embedding: list[float], top_k: int) -> list[Entity]:
        pass

class PostgreSQLMemoryStore(MemoryStore):
    """Impl√©mentation Day 1 : PostgreSQL + pgvector"""
    # ...

def get_memorystore() -> MemoryStore:
    provider = os.getenv("MEMORYSTORE_PROVIDER", "postgresql")
    if provider == "postgresql":
        return PostgreSQLMemoryStore(...)
    elif provider == "graphiti":  # Future r√©√©valuation (6 mois)
        return GraphitiMemoryStore(...)
    raise ValueError(f"Unknown provider: {provider}")
```

**Avantages** :
- Swap provider en 1 fichier (`memorystore.py`)
- Tests interface ind√©pendants de l'impl√©mentation (11 tests ABC)
- Pr√™t pour migration Graphiti/Neo4j si n√©cessaire (ao√ªt 2026)

---

### 4. **Migration 110k emails - Strat√©gie 3 phases robuste**

**Phase 1 : Classification via Claude Sonnet 4.5**
- Budget : $330 (110k emails √ó $0.003/classification)
- R√©sultat : 8 cat√©gories (medical, admin, personal, professional, financial, university, technical, other)
- Stockage : `ingestion.emails_raw` avec colonnes `category`, `confidence`, `classified_at`

**Phase 2 : Population graphe de connaissances**
- Extraction entit√©s : `Person`, `Organization`, `Event`, `Topic`
- Cr√©ation relations : `SENT_BY`, `BELONGS_TO`, `MENTIONS`, `RELATED_TO`
- Stockage : `knowledge.entities`, `knowledge.relations`

**Phase 3 : G√©n√©ration embeddings Voyage AI**
- Budget : $2 (110k emails √ó ~$0.00002/embedding)
- Mod√®le : `voyage-3-large` (1024 dimensions)
- Stockage : `knowledge.embeddings` avec pgvector
- Index : HNSW pour recherche rapide (<100ms)

**Scripts cr√©√©s** :
- `scripts/migrate_emails.py` (checkpointing, retry, resume, progress tracking)
- `scripts/extract_email_domains.py` (nouveau - voir Story 2.8)

**Robustesse** :
- ‚úÖ Checkpointing tous les 100 emails (resume apr√®s crash)
- ‚úÖ Retry backoff exponentiel (rate limits API)
- ‚úÖ Atomic writes (transactions PostgreSQL)
- ‚úÖ Validation int√©grit√© (6 bugs fix√©s lors code review v2)

---

## üî¥ What Could Be Improved

### 1. **Migration aveugle 110k emails - Gaspillage tokens identifi√©** ‚ö†Ô∏è

**Probl√®me** :
- Story 6.4 migre TOUS les 110k emails historiques sans filtrage
- Budget r√©el $332 (vs $45 estim√© PRD) = **7√ó d√©passement**
- Beaucoup d'emails sont probablement inutiles :
  - Commerce : Amazon, Netflix, eBay, Cdiscount (~15-20k emails ?)
  - Spam : newsletters, notifications automatiques (~10-15k emails ?)
  - R√©seaux sociaux : LinkedIn notifications, Facebook (~5-10k emails ?)
- Co√ªt LLM classification : ~$0.003/email ‚Üí **~$132 gaspill√©s** sur emails non pertinents

**Root cause** :
- Pas d'analyse pr√©alable des domaines sources
- Hypoth√®se implicite : "tous les emails sont pertinents"
- Pas de filtrage dans le design initial

---

### 2. **Solution propos√©e par Mainteneur : Filtrage intelligent permanent** üí°

**Insight cl√©** : La whitelist/blacklist ne doit pas √™tre juste pour la migration historique, mais un **syst√®me permanent** dans le pipeline email.

**Approche en 2 temps** :

#### **Temps 1 : Extraction domaines (data-driven)**
```bash
# Script Python simple
python scripts/extract_email_domains.py --min-count 10
# ‚Üí Output : domains_110k.csv
```

**CSV g√©n√©r√©** :
```csv
domain,count,first_seen,last_seen,category_guess,action,reason
amazon.fr,8234,2020-01,2026-02,commerce,,
gmail.com,12456,2019-03,2026-02,personal,,
univ-lille.fr,3890,2019-09,2026-01,university,,
chu-lille.fr,2103,2020-05,2026-02,medical,,
netflix.com,1567,2021-01,2026-02,streaming,,
doctolib.com,892,2022-03,2026-02,medical,,
```

**Processus** :
1. Script extrait domaines uniques depuis `emails_legacy` (2-3 secondes)
2. Colonne `category_guess` ajout√©e (heuristique : `*univ*` ‚Üí university, `*chu*` ‚Üí medical)
3. **Mainteneur annote manuellement** colonnes `action` (KEEP/SKIP) et `reason`
4. Import CSV annot√© ‚Üí table `ingestion.sender_filters`

#### **Temps 2 : Filtrage permanent dans pipeline**

**Architecture** :

```sql
-- Migration 030_sender_filters.sql
CREATE TABLE ingestion.sender_filters (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Pattern matching
    pattern TEXT NOT NULL UNIQUE,  -- '@amazon.fr', 'noreply@%', etc.
    pattern_type TEXT NOT NULL CHECK (pattern_type IN ('domain', 'email', 'prefix')),

    -- Action
    action TEXT NOT NULL CHECK (action IN ('whitelist', 'blacklist', 'auto')),
    reason TEXT,

    -- M√©triques √©conomie
    emails_filtered INT DEFAULT 0,
    tokens_saved INT DEFAULT 0,  -- ~1000 tokens/email
    cost_saved_usd DECIMAL(10,4) DEFAULT 0.00,

    -- Audit
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_matched_at TIMESTAMPTZ,
    is_active BOOLEAN DEFAULT true
);
```

**Int√©gration pipeline email (Story 2.2 modifi√©e)** :

```python
# agents/src/pipelines/email/consumer.py

async def process_email(email_data: dict):
    """Pipeline email avec filtrage AVANT classification"""

    sender = email_data['sender']

    # 1. CHECK FILTRES (NOUVEAU !)
    filter_action = await check_sender_filter(sender)

    if filter_action == 'blacklist':
        # Skip classification, √©conomise ~$0.003
        await db.execute("""
            INSERT INTO ingestion.emails_raw
            (message_id, sender, category, confidence, filtered)
            VALUES ($1, $2, 'filtered_blacklist', 1.0, true)
        """, email_data['message_id'], sender)

        # Update m√©triques √©conomie
        await db.execute("""
            UPDATE ingestion.sender_filters
            SET emails_filtered = emails_filtered + 1,
                tokens_saved = tokens_saved + 1000,
                cost_saved_usd = cost_saved_usd + 0.003,
                last_matched_at = NOW()
            WHERE pattern = get_domain_from_email($1)
        """, sender)

        logger.info("Email filtr√© (blacklist): %s", sender)
        return  # EXIT EARLY, pas de classification LLM

    # 2. Classification normale (si pas blacklist√©)
    result = await classify_email(email_data)  # Appel Claude
    # ...
```

**Commandes Telegram (Story 1.11 extension)** :

```python
# bot/handlers/commands.py

@router.message(Command("blacklist"))
async def cmd_blacklist(message: Message):
    """Blacklist un domaine pour √©conomiser tokens

    Usage: /blacklist @amazon.fr
    """
    pattern = message.text.split()[1]
    await db.execute("""
        INSERT INTO ingestion.sender_filters (pattern, pattern_type, action)
        VALUES ($1, 'domain', 'blacklist')
    """, pattern)
    await message.reply(f"‚úÖ Pattern blacklist√©: {pattern}")

@router.message(Command("filters"))
async def cmd_filters(message: Message):
    """Liste filtres actifs + m√©triques √©conomie"""
    filters = await db.fetch("""
        SELECT pattern, emails_filtered, cost_saved_usd
        FROM ingestion.sender_filters
        WHERE is_active = true
        ORDER BY emails_filtered DESC
        LIMIT 20
    """)

    total_saved = sum(f['cost_saved_usd'] for f in filters)
    msg = f"**Filtres actifs** ({len(filters)}):\n\n"
    for f in filters:
        msg += f"‚Ä¢ {f['pattern']}: {f['emails_filtered']} emails, ${f['cost_saved_usd']:.2f}\n"
    msg += f"\nüí∞ **Total √©conomis√©**: ${total_saved:.2f}"

    await message.reply(msg)
```

---

### 3. **Impact & ROI du filtrage intelligent**

**Migration 110k (optimis√©e)** :
- Emails pertinents estim√©s : ~66k (60% du total)
- Emails blacklist√©s : ~44k (40% spam/commerce/auto)
- Co√ªt optimis√© : ~$200 (vs $332 actuel)
- **√âconomie imm√©diate** : **$132**

**Runtime permanent** :
- Hypoth√®se : 50 emails commerciaux/spam par jour
- Co√ªt √©vit√© : 50 √ó $0.003 √ó 365 = **$54.75/an**

**ROI Story 2.8** :
- Co√ªt dev : ~15h √ó $50/h = $750
- √âconomie an 1 : $132 (migration) + $55 (runtime) = **$187**
- **Payback** : ~4 mois
- **√âconomie r√©currente** : $55/an ind√©finiment

---

### 4. **Budget Story 6.4 vs PRD - √âcart de pr√©vision**

**Probl√®me** :
- **PRD estimait** : $45 pour migration emails
- **R√©alit√©** : $332 (7√ó plus cher)
- **Causes** :
  - Volume sous-estim√© (PRD assumait ~15-30k emails ?)
  - Pas de filtrage pr√©vu dans le design initial
  - Co√ªt classification LLM non audit√© avant migration

**Le√ßon apprise** : Pour futures migrations bulk LLM, **TOUJOURS** :

1. **Scanner volume r√©el AVANT estimation**
   - Query SQL : `SELECT COUNT(*) FROM source_table`
   - Extraire √©chantillon repr√©sentatif (1000 lignes)

2. **Analyser distribution sources**
   - Domaines, types, cat√©gories
   - Identifier patterns spam/inutiles

3. **Pr√©voir filtrage intelligent d√®s le design**
   - Whitelist/blacklist explicite
   - Heuristiques simples (noreply@*, newsletters, etc.)

4. **Buffer estimation √ó2-3 pour impr√©vus**
   - Rate limits API
   - Erreurs n√©cessitant retry
   - Edge cases non pr√©vus

**Action** : Alice (PO) int√®grera cette checklist dans le grooming des futures stories impliquant LLM bulk.

---

## üé¨ Action Items

### **Action 1 : Cr√©er Story 2.8 "Filtrage sender intelligent & √©conomie tokens"** üî¥ CRITICAL

**Responsable** : √Ä assigner
**Priorit√©** : Haute (ROI $187/an)
**Taille** : M (12-18h)
**Epic** : Epic 2 (Pipeline Email Intelligent)

**Composants** :

1. **Migration 030** : Table `ingestion.sender_filters`
   - Colonnes : `pattern`, `pattern_type`, `action`, `emails_filtered`, `tokens_saved`, `cost_saved_usd`
   - Index sur `pattern` + `action`
   - Contraintes CHECK sur `action` IN ('whitelist','blacklist','auto')

2. **Script extraction domaines**
   ```bash
   python scripts/extract_email_domains.py \
     --source emails_legacy \
     --output domains_110k.csv \
     --min-count 10
   ```
   - Output CSV : domain, count, first_seen, last_seen, category_guess, action, reason
   - Heuristique `category_guess` pour faciliter tri manuel

3. **Pipeline email modification**
   - Fonction `check_sender_filter(sender: str) -> str` (whitelist/blacklist/auto)
   - Int√©gration dans `consumer.py` AVANT `classify_email()`
   - Update m√©triques √©conomie (`emails_filtered`, `tokens_saved`, `cost_saved_usd`)

4. **Commandes Telegram**
   - `/blacklist <pattern>` : Ajouter pattern blacklist
   - `/whitelist <pattern>` : Ajouter pattern whitelist
   - `/filters` : Liste filtres + m√©triques √©conomie
   - `/filters remove <pattern>` : Supprimer filtre
   - Rate limiting 10 req/min (DoS protection)

5. **Tests**
   - 15 unit tests : pattern matching, priority (email > domain > prefix), m√©triques
   - 5 integration tests : pipeline email avec filtres, update m√©triques
   - 3 E2E tests : workflow complet (blacklist ‚Üí email ‚Üí skip classification ‚Üí m√©triques)
   - Test √©conomie : 100 emails blacklist√©s = $0.30 track√©s

**Acceptance Criteria (5 ACs)** :

1. ‚úÖ Migration 030 cr√©e table `sender_filters` avec contraintes + index
2. ‚úÖ `check_sender_filter()` appel√© AVANT classification, skip si blacklist
3. ‚úÖ Commandes Telegram `/blacklist`, `/whitelist`, `/filters` op√©rationnelles
4. ‚úÖ Script `extract_email_domains.py` g√©n√®re CSV annotable
5. ‚úÖ 23+ tests (15 unit + 5 integ + 3 E2E) PASS, m√©triques √©conomie track√©es

**D√©pendances** :
- Story 2.1 (EmailEngine r√©ception) - ‚úÖ DONE
- Story 2.2 (Classification LLM) - ‚úÖ DONE
- Story 6.4 (Migration 110k) - ‚úÖ DONE

**Deadline sugg√©r√©e** : Avant fin Epic 2 (pour optimiser Stories 2.4+)

---

### **Action 2 : Am√©liorer estimations budgets LLM** üìä

**Responsable** : Alice (Product Owner)
**Contexte** : PRD Epic 6 estimait $45, r√©alit√© $332 (7√ó √©cart)

**Checklist grooming futures stories LLM bulk** :

- [ ] Scanner volume r√©el source (`SELECT COUNT(*)`)
- [ ] Extraire √©chantillon repr√©sentatif (1000 lignes)
- [ ] Analyser distribution (domaines, types, patterns spam)
- [ ] Pr√©voir filtrage intelligent (whitelist/blacklist)
- [ ] Buffer estimation √ó2-3 pour impr√©vus
- [ ] Valider avec √©quipe tech AVANT finalisation story

**Livrable** : Template grooming int√©gr√© dans workflow BMAD (checklist Notion/Linear)

---

### **Action 3 : Documenter pattern "Domain-based filtering"** üìö

**Responsable** : Charlie (Dev Lead)
**Timing** : Apr√®s Story 2.8 impl√©ment√©e
**Contexte** : Pattern r√©utilisable pour autres pipelines (OCR documents, fichiers NAS, etc.)

**Contenu doc `docs/patterns/domain-based-filtering.md`** :

1. **Architecture**
   - Table SQL `sender_filters` (schema, indexes, contraintes)
   - Factory pattern pour extensibilit√© (domain/email/prefix matching)

2. **Usage**
   ```python
   # Example : OCR documents
   if await check_source_filter(document.source) == 'blacklist':
       return  # Skip OCR, √©conomise compute
   ```

3. **Exemples code**
   - Extraction domaines/sources (`extract_*.py`)
   - Int√©gration pipeline (check AVANT op√©ration co√ªteuse)
   - Commandes Telegram gestion filtres

4. **ROI calculation**
   - Formule : `(volume_filtr√© √ó co√ªt_unitaire √ó 365) - co√ªt_dev`
   - Exemple Story 2.8 : $187/an

5. **R√©utilisabilit√©**
   - Pipeline OCR (Story 3.1) : filtrer documents commerciaux scann√©s
   - Desktop Search (Story 3.3) : filtrer dossiers temporaires/cache
   - Fichiers NAS (Story 3.4) : filtrer backups/logs volumineux

**Livrable** : Doc pattern + code examples, r√©f√©renc√© dans CLAUDE.md

---

## üîÆ Next Epic Preparation - Epic 7 Preview

**Epic 7** : **Agenda & Calendrier Multi-casquettes** (3 stories)

| Story | Titre | D√©pendances | Taille | Complexit√© |
|-------|-------|-------------|--------|------------|
| **7.1** | D√©tection √©v√©nements depuis emails | 2.2 (classification) | M (12-18h) | Moyenne |
| **7.2** | Sync bidirectionnelle Google Calendar | - | M (12-18h) | Moyenne |
| **7.3** | Calendrier multi-casquettes (SELARL/SCI/Perso) | 7.1, 7.2 | M (12-18h) | Moyenne |

**Bloqueurs identifi√©s** : ‚úÖ Aucun
- PostgreSQL knowledge graph op√©rationnel (Epic 6 ‚úÖ)
- Pipeline email classification op√©rationnel (Story 2.2 ‚úÖ)
- Google Calendar API : standard, doc Google excellente
- Pas de nouvelles d√©pendances lourdes

**Recommandation** : Terminer Epic 2 AVANT de d√©marrer Epic 7
- Story 2.4 (Extraction PJ) : in-progress
- Stories 2.5-2.7 : backlog
- **Raison** : Epic 7.1 d√©pend de Story 2.2 (extraction √©v√©nements depuis emails classifi√©s)

---

## üìä M√©triques Finales Epic 6

| M√©trique | Valeur | Commentaire |
|----------|--------|-------------|
| **Stories compl√©t√©es** | 4/4 (100%) | Toutes stories termin√©es avec succ√®s |
| **Tests cr√©√©s** | 75+ | 40 unit + 19 interface + 16+ integration |
| **Couverture code** | Excellente | 100% des modules critiques test√©s |
| **Budget LLM r√©el** | $332 | vs $45 PRD (+640%), Action 2 cr√©√©e |
| **Dur√©e Epic** | ~2-3 semaines | Estimation initiale : 3-4 semaines |
| **D√©cisions techniques** | 1 majeure | D19 : pgvector Day 1 (retire Qdrant) |
| **Bugs post-review** | 0 | Code review adversarial pass√©e |
| **√âconomie RAM** | ~600 Mo | Qdrant retir√© ‚Üí pgvector PostgreSQL |
| **R√©gression** | 0 | Zero r√©gression d√©tect√©e |

---

## üéØ Succ√®s Cl√©s

1. ‚úÖ **PostgreSQL knowledge graph op√©rationnel** (10 node types, 14 relations, 40 tests)
2. ‚úÖ **pgvector embeddings Day 1** (Qdrant retir√©, D√©cision D19, √©conomie RAM)
3. ‚úÖ **Memorystore adapter factory pattern** (extensible, 11 tests interface)
4. ‚úÖ **Migration 110k emails r√©ussie** (strat√©gie 3 phases, checkpointing robuste)
5. ‚úÖ **Tests exhaustifs** (75+ tests, 100% couverture critique, 0 bugs post-review)
6. ‚úÖ **Insight majeur Mainteneur** : Filtrage intelligent permanent ‚Üí Story 2.8 cr√©√©e

---

## üî¥ Am√©lioration Majeure

**Filtrage intelligent sender (Story 2.8)** :
- √âconomie migration : $132 (44k emails blacklist√©s)
- √âconomie runtime : $55/an (50 emails/jour filtr√©s)
- **ROI total an 1** : **$187**
- Payback : ~4 mois
- Pattern r√©utilisable : OCR, Desktop Search, NAS

---

## üìù Notes Additionnelles

### D√©cisions techniques Epic 6

**D19 (2026-02-09) : pgvector Day 1, Qdrant retir√©**
- **Contexte** : Architecture initiale pr√©voyait Qdrant pour embeddings
- **D√©cision** : pgvector dans PostgreSQL suffit pour 100k vecteurs, 1 utilisateur
- **Rationale** : Simplification stack, -600 Mo RAM, latence acceptable (<100ms)
- **R√©√©valuation** : Si >300k vecteurs OU latence >100ms
- **Fichiers modifi√©s** : docker-compose.yml, migration 008, memorystore.py, consumer.py, test_docker_compose.py + 15+ docs

### Pattern "Domain-based filtering" d√©couvert

**Contexte** : Mainteneur a identifi√© gaspillage tokens sur migration 110k emails (commerce, spam, auto).

**Solution** : Extraction domaines ‚Üí tri manuel ‚Üí filtrage permanent pipeline.

**G√©n√©ralisation** : Pattern applicable √† :
- Pipeline OCR (filtrer documents commerciaux scann√©s)
- Desktop Search (filtrer dossiers cache/temp)
- NAS sync (filtrer backups/logs)

**ROI** : √âconomie tokens/compute sur volume > 10k items.

---

## üöÄ Prochaines √âtapes

1. **Priorit√© 1** : Cr√©er Story 2.8 dans sprint-status.yaml (status `backlog`, priorit√© haute)
2. **Priorit√© 2** : Terminer Epic 2 (Stories 2.4-2.7)
3. **Priorit√© 3** : Impl√©menter Story 2.8 (ROI √©lev√©, $187/an √©conomis√©s)
4. **Priorit√© 4** : D√©marrer Epic 7 (Agenda & Calendrier)

---

**R√©trospective compl√©t√©e** : 2026-02-11
**Participants** : Mainteneur, Alice, Bob, Charlie
**Dur√©e** : ~90 minutes
**Actions cr√©√©es** : 3 (1 critical, 2 standard)
**Stories cr√©√©es** : 1 (Story 2.8)

---

*G√©n√©r√© par BMAD Retrospective Workflow v1.0*
