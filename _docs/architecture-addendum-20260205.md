# Architecture Friday 2.0 - Addendum Technique

**Date** : 2026-02-05
**Version** : 1.0
**Compl√©ment √†** : [architecture-friday-2.0.md](architecture-friday-2.0.md)

Ce document contient les clarifications techniques suppl√©mentaires issues de l'analyse adversariale m√©ta du 2026-02-05.

---

## 1. Presidio Pipeline - Performance & Benchmark

### 1.1 Probl√©matique

Pipeline Presidio est **obligatoire** avant tout LLM cloud (RGPD), mais impact latence non √©valu√©.

### 1.2 Benchmarks attendus

| Texte type | Taille | Entit√©s PII | Latence Presidio | Latence LLM | Total |
|------------|--------|-------------|------------------|-------------|-------|
| Email court | 500 chars | 2-3 | ~200-300ms | ~800ms | ~1s |
| Email long | 2000 chars | 5-10 | ~500-800ms | ~1.2s | ~2s |
| Document | 5000 chars | 10-20 | ~1-1.5s | ~2s | ~3.5s |

**Sources** :
- Presidio benchmark officiel : ~400-600ms pour 1000 chars (CPU i7, 8 threads)
- VPS-4 OVH (12 vCores) : performance similaire attendue

### 1.3 Strat√©gies d'optimisation

Si latence Presidio >1s devient probl√©matique :

1. **Cache anonymisation** : Textes identiques ‚Üí r√©utiliser mapping (gain ~80%)
2. **Async pipeline** : Presidio en background pour actions non-urgentes
3. **Batch processing** : Grouper 10 emails ‚Üí Presidio batch (gain ~30%)
4. **Downgrade d√©tection** : D√©sactiver entit√©s rares (IBAN, CRYPTO) si non critiques

### 1.4 Tests de performance

```python
# tests/performance/test_presidio_latency.py
@pytest.mark.performance
async def test_presidio_latency_email_500chars():
    text = generate_email_with_pii(length=500, pii_count=3)
    start = time.time()
    anonymized, tokens = await anonymize_text(text, "test")
    latency = time.time() - start

    assert latency < 0.5, f"Presidio trop lent: {latency}s (seuil: 0.5s)"
```

**Seuils acceptables** :
- Email court (500 chars) : <500ms
- Email long (2000 chars) : <1s
- Document (5000 chars) : <2s

---

## 2. Pattern Detection - Algorithme Feedback Loop

### 2.1 Probl√©matique

L'architecture dit "Friday d√©tecte les patterns r√©currents automatiquement" mais **aucun algorithme sp√©cifi√©**.

### 2.2 Algorithme de d√©tection

**√âtapes** :

1. **Collecte corrections** (via Trust Layer)
   - Antonio corrige une action ‚Üí `core.action_receipts.correction` rempli
   - Exemple: Correction email #1 : "URSSAF ‚Üí finance (√©tait: professional)"
   - Exemple: Correction email #2 : "Cotisations URSSAF ‚Üí finance (√©tait: professional)"

2. **Clustering s√©mantique** (nightly cron)
   ```python
   # services/metrics/pattern_detector.py
   async def detect_correction_patterns():
       # R√©cup√©rer corrections de la semaine
       corrections = await db.fetch("""
           SELECT module, action_type, input_summary, correction, created_at
           FROM core.action_receipts
           WHERE correction IS NOT NULL
           AND created_at > NOW() - INTERVAL '7 days'
       """)

       # Grouper par module/action
       grouped = group_by(corrections, key=lambda x: (x['module'], x['action_type']))

       for (module, action), corr_list in grouped.items():
           # Calculer similarit√© entre corrections (embeddings)
           embeddings = await embed_texts([c['correction'] for c in corr_list])  # Via adapters/embeddings.py (Voyage AI)
           similarity_matrix = cosine_similarity(embeddings)

           # D√©tecter clusters (seuil 0.85)
           clusters = find_clusters(similarity_matrix, threshold=0.85)

           for cluster in clusters:
               if len(cluster) >= 2:  # Pattern = 2+ corrections similaires
                   # Extraire pattern commun
                   pattern = extract_common_pattern(cluster)

                   # Proposer r√®gle √† Antonio via Telegram
                   await propose_rule_to_antonio(module, action, pattern, cluster)
   ```

3. **Proposition r√®gle** (Telegram inline buttons)
   ```
   üìã PATTERN D√âTECT√â (email.classify)

   2 corrections similaires :
   - "URSSAF ‚Üí finance"
   - "Cotisations URSSAF ‚Üí finance"

   R√®gle propos√©e :
   IF email contient "URSSAF" OR "cotisations"
   THEN category = "finance", priority = "high"

   [‚úÖ Cr√©er r√®gle] [‚úèÔ∏è Modifier] [‚ùå Ignorer]
   ```

4. **Validation Antonio** ‚Üí Insertion `core.correction_rules`

### 2.3 Extraction pattern commun

```python
def extract_common_pattern(corrections: list[dict]) -> dict:
    """
    Extrait le pattern commun de plusieurs corrections
    M√©thode: D√©tection mots-cl√©s r√©currents + cat√©gorie cible
    """
    # Mots-cl√©s communs
    all_keywords = []
    for corr in corrections:
        keywords = extract_keywords(corr['input_summary'])
        all_keywords.extend(keywords)

    # Fr√©quence mots-cl√©s
    keyword_freq = Counter(all_keywords)
    common_keywords = [kw for kw, freq in keyword_freq.items() if freq >= 2]

    # Cat√©gorie/output cible (majorit√©)
    target_outputs = [parse_correction(c['correction']) for c in corrections]
    target_category = Counter([o['category'] for o in target_outputs]).most_common(1)[0][0]

    return {
        'conditions': {
            'keywords': common_keywords,
            'min_match': 1  # Au moins 1 keyword doit matcher
        },
        'output': {
            'category': target_category,
            'confidence_boost': 0.1  # Boost confiance si r√®gle match
        }
    }
```

### 2.4 Faux positifs - Mitigation

**Risque** : 2 corrections diff√©rentes confondues par l'algo.

**Solution** :
- Seuil de similarit√© √©lev√© (0.85 sur embeddings)
- Validation manuelle Antonio avant activation r√®gle
- Option "Ignorer ce pattern" ‚Üí Blacklist

---

## 3. Profils RAM - Sources & Benchmarks

### 3.1 Probl√©matique

Estimations RAM (Whisper 4 Go, etc.) sans source cit√©e ‚Üí risque sous-estimation. Note : Ollama retir√© (D12), LLM via API cloud Claude Sonnet 4.5 (D17).

### 3.2 Sources par service

| Service | RAM estim√©e | Source | Notes |
|---------|-------------|--------|-------|
| ~~Ollama Nemo 12B~~ | ~~8 Go~~ | ~~Retir√© (D√©cision D12 + D17 : LLM cloud Claude Sonnet 4.5 via API Anthropic)~~ | ‚ùå Supprim√© |
| **Faster-Whisper** | ~4 Go | [Faster-Whisper GitHub](https://github.com/SYSTRAN/faster-whisper) (large-v3 model) | ‚úÖ Officiel |
| **Kokoro TTS** | ~2 Go | Estimation bas√©e sur mod√®les TTS similaires (Piper ~1.5 Go) | ‚ö†Ô∏è √Ä valider Story 1 |
| **Surya OCR** | ~2 Go | [Surya GitHub](https://github.com/VikParuchuri/surya) (detection + recognition models) | ‚úÖ Officiel |
| **Presidio + spaCy-fr** | ~1.5 Go | spaCy fr_core_news_lg (~500 Mo) + Presidio overhead (~1 Go) | ‚úÖ Benchmark interne |
| **PostgreSQL 16** | ~1-1.5 Go | Config `shared_buffers=512MB` + working memory | ‚úÖ Configuration |
| **Redis 7** | ~200 Mo | Base install + AOF overhead | ‚úÖ Benchmark |
| ~~**Qdrant**~~ | ~~1-2 Go~~ | ~~Retir√© (D√©cision D19 : pgvector dans PostgreSQL)~~ | ‚ùå Supprim√© |
| **n8n** | ~500 Mo | [n8n Docker docs](https://docs.n8n.io/hosting/installation/docker/) | ‚úÖ Officiel |
| **FastAPI Gateway** | ~200 Mo | Python asyncio + uvicorn workers | ‚úÖ Estimation standard |
| **Telegram Bot** | ~100 Mo | python-telegram-bot lib | ‚úÖ Estimation standard |
| **Caddy** | ~50 Mo | Caddy 2 reverse proxy | ‚úÖ Officiel |
| ~~**Zep**~~ | ~~500 Mo~~ | ~~Retir√© (Zep cess√© 2024)~~ | ‚ùå Supprim√© |

### 3.3 Marge d'erreur

**Estimations ‚úÖ valid√©es** (sources officielles) : ¬±10%
**Estimations ‚ö†Ô∏è √† valider** (extrapolations) : ¬±30%

**Total RAM optimiste** : ~11 Go (Ollama retir√© D12, LLM cloud D17, Qdrant retir√© D19)
**Total RAM pessimiste** : ~16 Go (Ollama retir√© D12, LLM cloud D17, Qdrant retir√© D19)
**VPS-4 disponible** : 48 Go
**Marge s√©curit√©** : ~32-37 Go (Ollama retir√© D12, LLM cloud Claude Sonnet 4.5 D17, Qdrant retir√© D19 ‚Üí pgvector dans PostgreSQL, services lourds ~8 Go)

### 3.4 Validation lors Story 1

```bash
# scripts/monitor-ram.sh (ajout logging d√©taill√©)
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}" \
  | tee logs/ram_usage_baseline.log

# Comparer avec estimations
python scripts/compare_ram_estimates.py \
  --baseline logs/ram_usage_baseline.log \
  --estimates config/profiles.py
```

**Action si √©cart >20%** : Mise √† jour `config/profiles.py` + alerte dans documentation.

---

## 4. OpenClaw - D√©cision finale & Alternative Heartbeat natif

### 4.1 D√©cision (2026-02-05)

**‚ùå Int√©gration OpenClaw Day 1 REJET√âE**

**Raison** : Score d√©cisionnel Antonio = 20/100 points ‚Üí Friday Natif + Heartbeat custom

| Crit√®re d√©cisionnel | R√©ponse Antonio | Points | Justification |
|---------------------|-----------------|--------|---------------|
| **Multi-chat n√©cessaire ?** | ‚ùå NON | +0 | Telegram suffit, pas besoin WhatsApp/Discord |
| **Skills identifi√©es (‚â•10) ?** | ‚ùå NON | +0 | Aucune skill ClawHub utile identifi√©e |
| **Heartbeat critique Day 1 ?** | ‚úÖ OUI | +20 | Proactivit√© essentielle pour Antonio |
| **Risque acceptable ?** | ‚ö†Ô∏è INCERTAIN | +0 | Pas √† l'aise avec 5-10% risque PII |

**Score total : 20 points < 30 ‚Üí Option 1 : Friday Natif**

### 4.2 Analyse ROI finale (donn√©es f√©vrier 2026)

**Co√ªts int√©gration OpenClaw complet** :

| Poste | Effort |
|-------|--------|
| Dev initial (Docker harden√©e, pipeline Presidio) | 15-20h |
| Audit skills (whitelist 10-15 skills) | 10-15h |
| Tests s√©curit√© (pentest, validation isolation) | 8-12h |
| Documentation | 5-8h |
| Maintenance annuelle (re-audit, mises √† jour) | 20-30h |
| **TOTAL ann√©e 1** | **58-85h** |

**B√©n√©fices OpenClaw pour Friday** :

| B√©n√©fice | Gain estim√© | Condition |
|----------|-------------|-----------|
| Heartbeat proactif | 5-10h √©conomis√©es | vs cron n8n manuel |
| Multi-chat int√©grations | 15-25h √©conomis√©es | ‚ùå Antonio n'en a pas besoin |
| Skills audit√©es | 0-50h √©conomis√©es | ‚ùå Aucune skill identifi√©e |
| **TOTAL r√©aliste Antonio** | **5-10h** | Heartbeat UNIQUEMENT |

**ROI calcul√©** :
```
Co√ªt = 70h (sc√©nario r√©aliste)
B√©n√©fice = 10h (heartbeat uniquement)
ROI = (10 - 70) / 70 = -86%  ‚ùå ROI CATASTROPHIQUE
```

### 4.3 √âtat OpenClaw f√©vrier 2026 (sources r√©centes)

**‚úÖ Progr√®s confirm√©s** :
- v2026.2.3 (04/02/2026) : Hardening s√©curit√© actif
- Sandbox validation (`filePath`, `capDrop: ALL`)
- Docker non-root par d√©faut (uid 1000)
- √âquipe r√©active (RCE patch√© rapidement)

**üö® Risques critiques persistants** :
- **341 skills malicieux sur 2,857 audit√©s = 12%** ([TheHackerNews 02/02/2026](https://thehackernews.com/2026/02/researchers-find-341-malicious-clawhub.html))
- Maintainer ClawHub admet : *"cannot be secured"*
- Bloomberg (04/02/2026) : *"security a work in progress"*
- Supply chain attack actif (27 jan - 2 f√©v 2026)

### 4.4 Alternative retenue : Heartbeat Engine natif Friday

**‚úÖ Story 2.5 : Heartbeat Engine natif** (~10h dev)

**Composants** :
```python
# agents/src/core/heartbeat.py
class FridayHeartbeat:
    """
    Heartbeat proactif Friday 2.0
    Inspir√© OpenClaw, mais int√©gration native
    """
    - Interval configurable (default 30min)
    - LLM d√©cide dynamiquement quoi v√©rifier (contexte-aware)
    - Checks enregistr√©s avec priorit√©s (high/medium/low)
    - Quiet hours (22h-8h)
    - Integration native Trust Layer (@friday_action)
```

**Exemples checks Day 1** :
- `check_urgent_emails` (high) ‚Üí Emails urgents non lus
- `check_financial_alerts` (medium) ‚Üí Alertes financi√®res, √©ch√©ances
- `check_thesis_reminders` (low) ‚Üí Deadlines th√®ses √©tudiants

**Avantages vs OpenClaw** :

| Dimension | OpenClaw | Heartbeat natif Friday | Delta |
|-----------|----------|------------------------|-------|
| **Co√ªt dev** | 70h | **10h** | ‚úÖ -86% |
| **Maintenance** | 20h/an | **2h/an** | ‚úÖ -90% |
| **Risque supply chain** | 12% skills malicieux | **0%** | ‚úÖ √âlimin√© |
| **Int√©gration Trust Layer** | Custom n√©cessaire | **Native** | ‚úÖ Seamless |
| **Debugging** | 2 syst√®mes | **1 syst√®me** | ‚úÖ Simplifi√© |
| **Contr√¥le code** | D√©pendance externe | **Total** | ‚úÖ Ma√Ætris√© |
| **Proactivit√©** | ‚úÖ Heartbeat | ‚úÖ **Heartbeat** | ‚öñÔ∏è √âquivalent |

**Verdict** : Heartbeat natif apporte 100% du b√©n√©fice recherch√© (proactivit√©) pour 14% du co√ªt OpenClaw.

### 4.5 Porte de sortie : R√©√©valuation ao√ªt 2026

**Conditions r√©√©valuation OpenClaw** :

**SI** dans 6 mois (ao√ªt 2026) :
1. Antonio identifie ‚â•10 skills ClawHub audit√©es utiles
2. Besoin multi-chat √©merge (WhatsApp, Discord)
3. √âcosyst√®me OpenClaw s'est stabilis√© (supply chain cleaner)
4. Heartbeat natif Friday s'av√®re insuffisant

**ALORS** : POC OpenClaw Phase 1 avec defense-in-depth :
- Docker harden√©e (non-root, capDrop ALL, network isol√©)
- Pipeline Presidio obligatoire (anonymisation avant skills)
- Whitelist skills audit√©e manuellement
- VPS-test s√©par√© (pas prod)
- Monitoring d√©taill√© (Falco ou √©quivalent)

**SINON** : Friday natif reste l'architecture d√©finitive.

**Documents techniques** :
- Spec Heartbeat Engine : [agents/docs/heartbeat-engine-spec.md](../agents/docs/heartbeat-engine-spec.md)
- Decision Log : [docs/DECISION_LOG.md](../docs/DECISION_LOG.md#2026-02-05--d√©cision-openclaw---friday-natif--heartbeat-custom)
- Analyse comparative : Session Party Mode 2026-02-05 (sources OpenClaw v2026.2.3)

---

## 5. Configuration n8n - Obtention variables d'environnement

### 5.1 Probl√©matique

Workflows n8n mentionnent `${TELEGRAM_CHAT_ID}` mais aucun doc n'explique comment obtenir ces valeurs.

### 5.2 Guide complet obtention variables

#### **TELEGRAM_BOT_TOKEN**

**√âtapes** :
1. Ouvrir Telegram ‚Üí Rechercher [@BotFather](https://t.me/botfather)
2. Envoyer `/newbot`
3. Choisir nom (ex: "Friday 2.0") + username (ex: @friday_antonio_bot)
4. BotFather r√©pond avec token : `1234567890:ABCdefGHIjklMNOpqrsTUVwxyz`
5. Copier token ‚Üí `.env` : `TELEGRAM_BOT_TOKEN=1234567890:ABC...`

#### **TELEGRAM_CHAT_ID** (Antonio)

**M√©thode 1 - Via bot @userinfobot** (plus simple) :
1. Ouvrir Telegram ‚Üí Rechercher [@userinfobot](https://t.me/userinfobot)
2. Envoyer `/start`
3. Bot r√©pond : "Your ID: `123456789`"
4. Copier ‚Üí `.env` : `TELEGRAM_CHAT_ID=123456789`

**M√©thode 2 - Via API Telegram** :
1. Envoyer message √† votre bot Friday
2. Appeler API : `https://api.telegram.org/bot<TOKEN>/getUpdates`
3. Chercher `"chat":{"id":123456789}` dans la r√©ponse JSON
4. Copier ID

#### **EMAILENGINE_TOKEN**

**√âtapes** :
1. Lancer EmailEngine : `docker compose up -d emailengine`
2. Acc√©der UI : `http://friday.local/emailengine` (via Caddy) ou `http://localhost:3000`
3. Premier lancement ‚Üí Cr√©er compte admin
4. Settings ‚Üí API ‚Üí "Generate new token"
5. Copier token ‚Üí `.env` : `EMAILENGINE_TOKEN=ee_...`

#### **ANTHROPIC_API_KEY**

**√âtapes** :
1. Cr√©er compte sur [console.anthropic.com](https://console.anthropic.com/)
2. Billing ‚Üí Ajouter carte (cr√©dits API)
3. API Keys ‚Üí "Create Key"
4. Copier ‚Üí `.env` : `ANTHROPIC_API_KEY=sk-ant-...`

> **Note (D17)** : Remplacement de Mistral par Claude Sonnet 4.5 (Anthropic). Mod√®le utilis√© : `claude-sonnet-4-5-20250514` via API Anthropic.

#### **DEEPGRAM_API_KEY** (fallback STT)

**√âtapes** :
1. Cr√©er compte sur [deepgram.com](https://deepgram.com/)
2. Console ‚Üí API Keys ‚Üí "Create a key"
3. Copier ‚Üí `.env` : `DEEPGRAM_API_KEY=...`

### 5.3 Script de v√©rification

```bash
# scripts/verify_env.sh
# V√©rifie que toutes les variables requises sont d√©finies

required_vars=(
  "TELEGRAM_BOT_TOKEN"
  "TELEGRAM_CHAT_ID"
  "ANTHROPIC_API_KEY"
  "EMAILENGINE_TOKEN"
  "POSTGRES_PASSWORD"
  "REDIS_PASSWORD"
)

for var in "${required_vars[@]}"; do
  if [ -z "${!var}" ]; then
    echo "‚ùå Variable manquante: $var"
    exit 1
  fi
done

echo "‚úÖ Toutes les variables requises sont d√©finies"
```

---

## 6. Graphe de connaissances - Population initiale (Migration)

### 6.1 Probl√©matique

L'architecture sp√©cifie comment peupler le graphe **au fil de l'eau** (nouveaux emails ‚Üí cr√©ation n≈ìuds/relations) mais PAS la **migration initiale** de 110 000 emails existants + documents d√©j√† archiv√©s.

### 6.2 Strat√©gie migration graphe

**D√©cision** : La migration emails inclut **AUSSI** la population graphe initiale.

**Workflow migration enrichi** :

```python
# scripts/migrate_emails.py (enrichi)
async def migrate_email(self, email: dict):
    # 1. Classification (d√©j√† impl√©ment√©)
    classification = await self.classify_email(email)

    # 2. Insertion PostgreSQL (d√©j√† impl√©ment√©)
    await self.db.execute(...)

    # 3. NOUVEAU : Population graphe
    await self.populate_graph_from_email(email, classification)

    # 4. Publish event Redis
    # ...

async def populate_graph_from_email(self, email: dict, classification: dict):
    """
    Cr√©e n≈ìuds + relations dans Zep/Graphiti pour un email
    """
    # Cr√©er n≈ìud Email
    email_node = await graphiti.create_node(
        type="Email",
        properties={
            "message_id": email['message_id'],
            "subject": email['subject'],
            "date": email['received_at'],
            "category": classification['category'],
            "priority": classification['priority']
        }
    )

    # Cr√©er n≈ìud Person (sender) si n'existe pas
    sender_node = await graphiti.get_or_create_node(
        type="Person",
        properties={"email": email['sender']}
    )

    # Cr√©er relation SENT_BY
    await graphiti.create_edge(
        from_node=email_node,
        to_node=sender_node,
        type="SENT_BY",
        properties={"timestamp": email['received_at']}
    )

    # Extraction entit√©s NER
    entities = await extract_entities_ner(email['body_text'])
    for entity in entities:
        entity_node = await graphiti.get_or_create_node(
            type="Entity",
            properties={
                "name": entity.text,
                "entity_type": entity.label_
            }
        )
        await graphiti.create_edge(
            from_node=email_node,
            to_node=entity_node,
            type="MENTIONS",
            properties={"context": entity.context}
        )
```

### 6.3 Ordre population

**S√©quence optimale** :

1. **PostgreSQL d'abord** (rapide, 9h)
2. **Graphe ensuite** (plus lent, ~15-20h suppl√©mentaires)
3. **Vectoriel en dernier** (pgvector embeddings dans `knowledge.embeddings`, parall√©lisable) (D19)

**Rationale** : Si la migration graphe √©choue, PostgreSQL est d√©j√† peupl√©. On peut retry la population graphe sans tout recommencer.

### 6.4 Dur√©e totale migration

| Phase | Dur√©e | Parall√©lisable ? |
|-------|-------|------------------|
| Classification + Insert PostgreSQL | ~9h | Non (rate limit API Claude) |
| Population graphe (n≈ìuds + relations) | ~15-20h | Oui (batch 100 emails) |
| Embeddings pgvector (D19) | ~6-8h | Oui (batch 1000 docs) |
| **TOTAL** | **~30-37h** | Nuit + week-end |

**Strat√©gie ex√©cution** :
- Vendredi soir : Lancer migration
- Samedi matin : Checkpoint + v√©rification progression
- Dimanche soir : Migration termin√©e + validation

### 6.5 Checkpointing graphe

```python
# Extension checkpoint pour graphe
checkpoint_data = {
    'postgres_processed': 110000,
    'graph_processed': 84000,  # NOUVEAU
    'pgvector_processed': 60000,  # NOUVEAU (D19 : pgvector remplace Qdrant)
    'last_email_id': 'abc123'
}
```

**Resume partiel** : Si graphe crash √† 84k/110k, reprendre √† 84k (pas besoin de refaire PostgreSQL).

### 6.6 Validation post-migration

```python
# scripts/validate_migration.py
async def validate_graph_population():
    # V√©rifier coh√©rence PostgreSQL vs Graphe
    email_count_postgres = await db.fetchval("SELECT COUNT(*) FROM ingestion.emails")
    email_count_graph = await graphiti.count_nodes(type="Email")

    assert email_count_graph == email_count_postgres, \
        f"Graphe incomplet: {email_count_graph}/{email_count_postgres}"

    # V√©rifier relations SENT_BY
    edges_count = await graphiti.count_edges(type="SENT_BY")
    assert edges_count == email_count_postgres, \
        "Relations SENT_BY manquantes"

    print(f"‚úÖ Graphe valid√©: {email_count_graph} emails + {edges_count} relations")
```

---

---

## 7. Trust Retrogradation - Definition formelle des metriques

### 7.1 Problematique

L'architecture dit "accuracy <90% sur 1 semaine" mais ne definit pas formellement la formule, la granularite, ni les seuils minimaux.

### 7.2 Formule d'accuracy

```
accuracy(module, action, semaine) = 1 - (corrections / total_actions)

Ou :
- corrections = nombre d'actions corrigees par Antonio dans la semaine
- total_actions = nombre total d'actions executees (status: auto, propose validee)
```

### 7.3 Regles de retrogradation

| Condition | Action | Direction |
|-----------|--------|-----------|
| accuracy < 90% sur 1 semaine ET total_actions >= 10 | auto -> propose | Retrogradation |
| accuracy < 70% sur 1 semaine ET total_actions >= 5 | propose -> blocked | Retrogradation |
| accuracy >= 95% sur 2 semaines consecutives ET total_actions >= 20 | propose -> auto | Promotion |
| accuracy >= 90% sur 4 semaines consecutives ET total_actions >= 10 | blocked -> propose | Promotion |

**Seuil minimum d'echantillon** : Pas de changement de trust level si total_actions < 5 dans la semaine (echantillon insuffisant).

### 7.4 Granularite

La retrogradation s'applique **par module ET par action** (pas globalement) :
- `email.classify` peut etre retrograde sans affecter `email.draft_reply`
- Chaque paire (module, action) a son propre historique d'accuracy

### 7.5 Timing

- Calcul : Cron nightly a 02:00 (nightly_metrics)
- Fenetre : 7 jours glissants (pas semaine calendaire)
- Notification : Antonio recoit un message Telegram si un trust level change
- Override : Antonio peut forcer un trust level via `/confiance set email.classify auto`

### 7.6 Anti-oscillation

Pour eviter les oscillations AUTO <-> PROPOSE :
- Apres retrogradation, minimum 2 semaines avant promotion possible
- Apres promotion, minimum 1 semaine avant retrogradation possible

---

## 8. Healthcheck - Liste complete des services

### 8.1 Configuration healthcheck etendue

```python
HEALTH_CHECKS: dict[str, HealthCheckConfig] = {
    # Services critiques (overall health = CRITICAL si down)
    "postgres": HealthCheckConfig(
        func=check_postgres,
        timeout_ms=2000,
        critical=True,
        dependencies=[],
    ),
    "redis": HealthCheckConfig(
        func=check_redis,
        timeout_ms=1000,
        critical=True,
        dependencies=[],
    ),
    # Qdrant retir√© (D19) - embeddings via pgvector dans PostgreSQL
    # Services importants (overall health = DEGRADED si down)
    "n8n": HealthCheckConfig(
        func=lambda: check_http("http://n8n:5678/healthz"),
        timeout_ms=3000,
        critical=False,
        dependencies=["postgres", "redis"],
    ),
    "emailengine": HealthCheckConfig(
        func=lambda: check_http("http://emailengine:3000/health"),
        timeout_ms=3000,
        critical=False,
        dependencies=["postgres"],
    ),
    "presidio": HealthCheckConfig(
        func=lambda: check_http("http://presidio-analyzer:5001/health"),
        timeout_ms=2000,
        critical=False,
        dependencies=[],
    ),
    # Services lourds residents
    # Ollama retir√© (D12) - LLM via API cloud Claude Sonnet 4.5 (D17)
    "faster-whisper": HealthCheckConfig(
        func=lambda: check_http("http://whisper:8080/health"),
        timeout_ms=3000,
        critical=False,
        dependencies=[],
    ),
    "kokoro-tts": HealthCheckConfig(
        func=lambda: check_http("http://kokoro:8001/health"),
        timeout_ms=3000,
        critical=False,
        dependencies=[],
    ),
    "surya-ocr": HealthCheckConfig(
        func=lambda: check_http("http://surya:8002/health"),
        timeout_ms=3000,
        critical=False,
        dependencies=[],
    ),
}

# Cache healthcheck pour eviter surcharge (5 secondes TTL)
HEALTH_CHECK_CACHE_TTL_SECONDS = 5
```

### 8.2 Semantique des resultats

| Resultat | Condition | Signification |
|----------|-----------|---------------|
| `healthy` | Tous les checks critical=True passent | Systeme pleinement operationnel |
| `degraded` | Checks critical OK, 1+ non-critical echoue | Systeme partiellement operationnel |
| `unhealthy` | 1+ check critical echoue | Systeme non operationnel |

---

## 9. Securite - Complements

### 9.1 Anonymisation - Lifecycle du mapping

Les mappings Presidio (ex: `[PERSON_1] -> "Jean Dupont"`) suivent ce cycle :

| Phase | Duree | Stockage | RGPD |
|-------|-------|----------|------|
| En cours (session LLM) | Duree de la requete | Memoire uniquement | OK (ephemere) |
| Post-deanonymisation | Immediat | Supprime de memoire | OK |
| Audit trail | 30 jours | `core.action_receipts.payload` (chiffre pgcrypto) | OK (chiffre) |
| Purge | Apres 30 jours | Supprime definitivement | OK (droit a l'oubli) |

**Regle** : Les mappings NE SONT JAMAIS stockes en clair. En base, seul le texte anonymise est stocke. Le mapping temporaire existe uniquement en memoire pendant la duree de la requete LLM.

#### **Solution debugging Trust Layer** (ajout 2026-02-05, code review adversarial CRITIQUE #4)

**Problematique** : Comment Antonio corrige-t-il une action via Trust Layer si le texte est anonymise dans les receipts ?

**Solution retenue** : Stockage chiffre pgcrypto + acces commande Telegram `/receipt <id> --decrypt`

1. **Stockage mappings dans `core.action_receipts`** :
   ```sql
   ALTER TABLE core.action_receipts
   ADD COLUMN encrypted_mapping BYTEA;  -- Chiffre via pgcrypto
   ```

2. **Chiffrement insertion** :
   ```python
   # agents/src/middleware/trust.py
   async def store_receipt(..., presidio_mapping: dict):
       mapping_json = json.dumps(presidio_mapping)
       # Chiffrer avec cle symetrique pgcrypto (AES-256)
       encrypted = await db.fetchval(
           "SELECT pgp_sym_encrypt($1, $2)",
           mapping_json,
           os.getenv("PRESIDIO_MAPPING_KEY")  # Cle dans .env chiffre via age/SOPS
       )
       # Stocker dans receipt
       await db.execute(
           "UPDATE core.action_receipts SET encrypted_mapping = $1 WHERE id = $2",
           encrypted, receipt_id
       )
   ```

3. **Dechiffrement via Telegram** :
   ```python
   # bot/commands/receipt.py
   @friday_action(module="trust", action="decrypt_receipt", trust_default="blocked")
   async def handle_receipt_decrypt(receipt_id: str, user_id: int):
       # Verifier que user = Antonio uniquement
       if user_id != ANTONIO_TELEGRAM_ID:
           return "‚ùå Acces refuse (admin uniquement)"

       # Dechiffrer mapping
       encrypted = await db.fetchval(
           "SELECT encrypted_mapping FROM core.action_receipts WHERE id = $1",
           receipt_id
       )
       if not encrypted:
           return "‚ö†Ô∏è  Pas de mapping disponible"

       mapping_json = await db.fetchval(
           "SELECT pgp_sym_decrypt($1, $2)",
           encrypted,
           os.getenv("PRESIDIO_MAPPING_KEY")
       )
       mapping = json.loads(mapping_json)

       # Log audit trail (RGPD : tracer acces donnees)
       await db.execute(
           "INSERT INTO core.audit_logs (event, user_id, receipt_id, timestamp) "
           "VALUES ('decrypt_mapping', $1, $2, NOW())",
           user_id, receipt_id
       )

       # Retourner texte dechiffre (ephemere, pas stocke)
       return f"üîì Mapping dechiffre:\n{format_mapping(mapping)}"
   ```

4. **Usage Antonio** :
   ```
   /receipt abc-123            # Voir receipt avec texte anonymise
   /receipt abc-123 --decrypt  # Dechiffrer temporairement pour debug (audit trail)
   ```

**Garanties RGPD** :
- ‚úÖ Mappings chiffres au repos (pgcrypto AES-256)
- ‚úÖ Cle de chiffrement dans .env chiffre (age/SOPS)
- ‚úÖ Acces restreint Antonio uniquement
- ‚úÖ Audit trail de chaque dechiffrement
- ‚úÖ Purge automatique apres 30 jours (retention limitee)
- ‚úÖ Pas d'affichage en clair dans logs (mapping ephemere en memoire Telegram)

### 9.2 Redis ACL

Chaque service a ses propres permissions Redis :

```
# redis.conf
user gateway on >gateway_password ~friday:* &* +@read +@write +@pubsub
user n8n on >n8n_password ~n8n:* &* +@read +@write
user alerting on >alerting_password ~* &* +@read +@pubsub -@write
user default off
```

**Principe** : Moindre privilege. Le service alerting ne peut QUE lire et s'abonner, pas ecrire.

### 9.3 Tailscale - Authentification renforcee

**Obligatoire avant mise en production** :
- 2FA active sur le compte Tailscale (TOTP ou hardware key)
- Device authorization active (nouveaux devices requierent approbation)
- Key expiry = 90 jours (rotation automatique)
- SSH via Tailscale uniquement (port 22 ferme sur l'interface publique)

### 9.4 Backups - Chiffrement en transit et au repos

| Phase | Chiffrement | Methode |
|-------|-------------|---------|
| En transit (VPS -> PC) | TLS via Tailscale (WireGuard) | Automatique |
| Au repos (VPS) | age (fichier .dump) | `age -R recipients.txt backup.dump > backup.dump.age` |
| Au repos (PC) | Volume chiffre OS | BitLocker (Windows) / LUKS (Linux) |

---

## 10. Zep/Graphiti - Avertissement maturite

> **Avertissement (Feb 2026)** : Zep a cesse ses operations en 2024. Graphiti est en phase early-stage.
>
> **Decision provisoire** : Demarrer avec `adapters/memorystore.py` abstraction. Implementer d'abord
> une version simplifiee basee sur PostgreSQL (tables knowledge.* + pgvector pour embeddings via `knowledge.embeddings` colonne `vector(1024)` + index HNSW) (D19).
> Si Graphiti atteint la maturite v1.0 stable, migration via adaptateur.
> Sinon, Neo4j Community Edition comme alternative.
> Reevaluation Qdrant si >300k vecteurs ou latence pgvector >100ms (D19).
>
> **Criteres de migration vers Graphiti** :
> - Version stable >= 1.0 publiee
> - Communaute active (>500 stars GitHub, releases regulieres)
> - Documentation API complete
> - Tests de charge valides sur dataset comparable (100k+ entites)

Les references a Zep dans les sections precedentes (6.2 notamment) doivent etre lues comme utilisant l'abstraction `adapters/memorystore.py` qui pourra pointer vers PostgreSQL, Graphiti, ou Neo4j selon la decision finale.

---

## 11. Strat√©gie de Notification : Telegram Topics Architecture

### 11.1 Contexte & Probl√©matique

**Date de d√©cision** : 2026-02-05
**Participants** : Antonio (Product Owner), Winston (Architect), Mary (Analyst), Amelia (Dev), via BMAD Party Mode

**Probl√®me identifi√©** :

L'architecture initiale sp√©cifiait "canal unique Telegram + progressive disclosure" (CLAUDE.md section Observability & Trust Layer) mais cette approche pr√©sente un risque critique de **chaos informationnel** :

- Alertes syst√®me critiques (RAM >85%, services down)
- Validations trust=propose (inline buttons requ√©rant action imm√©diate)
- Actions automatiques (trust=auto) informatives
- Messages proactifs heartbeat (toutes les 30min)
- M√©triques et logs non-critiques
- Conversations bidirectionnelles avec Friday (commandes, questions)

**Tout m√©lang√© dans un seul fil = illisible et contre-productif.**

Antonio a soulev√© la question : *"Si tout arrive sur le m√™me canal que le bot... tout √ßa risque d'√™tre illisible"* ‚Üí Discussion Party Mode a valid√© cette pr√©occupation et conduit √† l'architecture ci-dessous.

### 11.2 D√©cision : Supergroup avec 5 Topics Sp√©cialis√©s

**Architecture retenue** :

Supergroup Telegram "Friday 2.0 Control" avec 5 topics :

```mermaid
graph TB
    subgraph "Friday 2.0 Supergroup"
        T1[üí¨ Chat & Proactive<br/>DEFAULT, BIDIRECTIONNEL]
        T2[üì¨ Email & Communications]
        T3[ü§ñ Actions & Validations]
        T4[üö® System & Alerts]
        T5[üìä Metrics & Logs]
    end

    Antonio((Antonio)) <-->|Conversations| T1
    Heartbeat[Heartbeat Engine] -->|Messages proactifs| T1
    EmailAgent[Email Agent] -->|Classifications| T2
    TrustLayer[Trust Layer] -->|Validations| T3
    Monitor[System Monitor] -->|Alertes| T4
    Metrics[Metrics Service] -->|Stats| T5

    style T1 fill:#90EE90
    style Antonio fill:#FFD700
```

#### Topic 1: üí¨ Chat & Proactive (DEFAULT, BIDIRECTIONNEL)

**R√¥le** : Conversation principale continue avec Friday

**Contenu** :
- Conversations Antonio ‚Üî Friday (questions, commandes, r√©ponses)
- Commandes : `/status`, `/journal`, `/receipt`, `/confiance`, `/stats`
- Heartbeat checks proactifs (Friday initie toutes les 30min)
- Suggestions contextuelles et reminders (deadlines th√®se, √©ch√©ances)
- Message d'onboarding au premier join

**Caract√©ristiques** :
- Topic par d√©faut du supergroup (ouverture automatique)
- Bidirectionnel : Antonio et Friday √©changent naturellement
- Pr√©serve le contexte conversationnel (heartbeat ‚Üí question ‚Üí r√©ponse dans m√™me fil)

**Rationale fusion Chat + Heartbeat** : Antonio a sugg√©r√© de fusionner les topics "General/Chat" et "Proactive/Heartbeat" initialement s√©par√©s. Rationale valid√©e par Mary (Analyst) : *"Le heartbeat N'EST PAS une notification passive - c'est une invitation √† interagir"*. S√©parer conversation et proactivit√© fragmenterait le dialogue naturel.

#### Topic 2: üì¨ Email & Communications

**R√¥le** : Notifications li√©es aux emails et communications

**Contenu** :
- Classifications email automatiques (trust=auto)
- Pi√®ces jointes d√©tect√©es et extraites
- Validations r√©ponses email (si trust=propose pour email.draft_reply)
- Emails urgents identifi√©s (priorit√© high)
- R√©sultats Desktop Search

**Modules rout√©s** : `email`, `desktop_search`

#### Topic 3: ü§ñ Actions & Validations

**R√¥le** : Actions n√©cessitant validation humaine ou feedback

**Contenu** :
- Toutes actions trust=propose avec inline buttons (Approve/Reject)
- Corrections appliqu√©es par Antonio (feedback loop)
- Trust level changes (auto‚Üípropose, propose‚Üíauto)
- Feedbacks trait√©s et r√®gles cr√©√©es

**Events rout√©s** : `action.pending`, `action.corrected`, `trust.changed`

#### Topic 4: üö® System & Alerts

**R√¥le** : Sant√© syst√®me et alertes critiques

**Contenu** :
- Alertes RAM >85% (moniteur VPS-4 48 Go, seuil 40.8 Go)
- Services down/up (PostgreSQL, Redis, n8n, etc.) (D19 : Qdrant retir√©, pgvector dans PostgreSQL)
- Pipeline errors critiques
- Backup status (success/failure)
- Security events (tentatives acc√®s Tailscale, anomalies)

**Priorit√©s rout√©es** : `critical`, `warning`

#### Topic 5: üìä Metrics & Logs

**R√¥le** : M√©triques, statistiques, logs non-critiques

**Contenu** :
- Actions auto (trust=auto) ex√©cut√©es avec succ√®s
- M√©triques nightly aggregation (trust accuracy par module)
- Stats trust accuracy hebdomadaires
- Logs non-critiques (debug, info)

**Priorit√©s rout√©es** : `info`, `debug`

### 11.3 Rationale Architectural

**Pourquoi 5 topics et pas 3 ou 7 ?**

- **Topic 1 (Chat & Proactive)** = Conversation bidirectionnelle continue
  - C'est LA conversation principale avec Friday
  - Fusion heartbeat + chat valid√©e pour pr√©server contexte conversationnel

- **Topics 2-5** = Flux de notifications sp√©cialis√©s par domaine
  - Permettent filtrage granulaire via mute/unmute natif Telegram
  - S√©paration par fonction (Email, Actions, System, Logs)

**Principe de s√©paration** :
- **Bidirectionnel** (Topic 1) vs **Unidirectionnel** (Topics 2-5)
- **Conversationnel** (Topic 1) vs **Notificationnel** (Topics 2-5)

**Granularit√© valid√©e** : 5 topics = √©quilibre entre simplicit√© (pas 10+ topics) et sp√©cialisation (pas 2-3 trop g√©n√©riques).

### 11.4 Routing Logic

**Algorithme de routage des √©v√©nements** :

```python
# services/alerting/telegram_notifier.py
def route_event_to_topic(event: Event) -> int:
    """
    Route un √©v√©nement vers le topic Telegram appropri√©
    Retourne le thread_id du topic cible
    """
    # Heartbeat et messages proactifs ‚Üí Chat & Proactive
    if event.source in ["heartbeat", "proactive"]:
        return TOPIC_CHAT_PROACTIVE

    # Module email/desktop_search ‚Üí Email & Communications
    if event.module in ["email", "desktop_search"]:
        return TOPIC_EMAIL_COMMS

    # Events action.* ‚Üí Actions & Validations
    if event.type.startswith("action."):
        return TOPIC_ACTIONS_VALIDATIONS

    # Priorit√© critique/warning ‚Üí System & Alerts
    if event.priority in ["critical", "warning"]:
        return TOPIC_SYSTEM_ALERTS

    # Default : Metrics & Logs
    return TOPIC_METRICS_LOGS
```

**Ordre de priorit√©** : Les conditions sont √©valu√©es s√©quentiellement. Un √©v√©nement `action.pending` avec `priority=critical` ira dans **Actions & Validations** (premi√®re condition match√©e), pas System.

### 11.5 D√©cisions Compl√©mentaires

#### Quiet Hours : NON impl√©ment√©s en code

**Rationale** : Les t√©l√©phones ont nativement des fonctionnalit√©s de gestion des notifications :
- Do Not Disturb (DND)
- Focus modes (iOS, Android)
- Scheduled silence (22h-8h configurable)

**Pourquoi recoder √ßa ?** On donne la granularit√© (topics), Antonio configure son t√©l√©phone selon ses besoins.

**Flexibilit√© utilisateur** : Antonio peut muter/unmuter topics selon le contexte :
- **Mode Normal** : Tous topics actifs ‚Üí voit tout en temps r√©el
- **Mode Focus** : Mute Email + Metrics, garde Actions + System ‚Üí validations + alertes uniquement
- **Mode Deep Work** : Mute tout sauf System ‚Üí alertes critiques uniquement
- **Mode Vacances** : Mute tout ‚Üí check manuel quand il veut

#### Filtrage par module : OUI

Chaque module Friday route ses √©v√©nements vers le topic appropri√© selon sa configuration.

**Configuration centralis√©e** : `config/telegram.yaml` (voir section 11.6)

#### Contr√¥le utilisateur natif Telegram

- **Mute topic** : Clic droit ‚Üí Mute (1h, 8h, jusqu'√† r√©activation)
- **Notifications push** : Configurables par topic (silencieux, vibration, son)
- **Historique consultable** : Topics mut√©s restent consultables manuellement

### 11.6 Configuration Technique

**Fichier** : `config/telegram.yaml`

```yaml
supergroup:
  chat_id: ${TELEGRAM_SUPERGROUP_ID}
  default_topic_id: ${TOPIC_CHAT_PROACTIVE_ID}

topics:
  chat_proactive:
    thread_id: ${TOPIC_CHAT_PROACTIVE_ID}
    name: "Chat & Proactive"
    default: true
    bidirectional: true
    handlers:
      - commands           # /status, /journal, etc.
      - questions          # "r√©sume mes emails urgents"
      - conversations      # chat libre
      - heartbeat_checks   # Friday initie (toutes les 30min)
      - reminders          # deadlines th√®se, √©ch√©ances
      - suggestions        # recommandations contextuelles

  email_comms:
    thread_id: ${TOPIC_EMAIL_ID}
    name: "Email & Communications"
    modules:
      - email
      - desktop_search

  actions_validations:
    thread_id: ${TOPIC_ACTIONS_ID}
    name: "Actions & Validations"
    events:
      - action.pending
      - action.corrected
      - trust.changed

  system_alerts:
    thread_id: ${TOPIC_SYSTEM_ID}
    name: "System & Alerts"
    priority:
      - critical
      - warning

  metrics_logs:
    thread_id: ${TOPIC_METRICS_ID}
    name: "Metrics & Logs"
    priority:
      - info
      - debug
```

**Variables d'environnement requises** (`.env`) :

```bash
TELEGRAM_SUPERGROUP_ID=<chat_id du supergroup>
TOPIC_CHAT_PROACTIVE_ID=<thread_id topic 1>
TOPIC_EMAIL_ID=<thread_id topic 2>
TOPIC_ACTIONS_ID=<thread_id topic 3>
TOPIC_SYSTEM_ID=<thread_id topic 4>
TOPIC_METRICS_ID=<thread_id topic 5>
```

**Obtention des thread IDs** : Voir guide technique `docs/telegram-topics-setup.md` (√† cr√©er Story 1.6).

### 11.7 Onboarding UX

Quand Antonio rejoint le supergroup la premi√®re fois, Friday envoie un **message onboarding dans Chat & Proactive** :

```
üéâ Bienvenue dans Friday 2.0 Control, Antonio !

üìö Guide rapide des topics :

üí¨ Chat & Proactive (ici) - Conversations avec Friday, heartbeat, reminders
üì¨ Email & Communications - Classifications email et pi√®ces jointes
ü§ñ Actions & Validations - Approbations requises (buttons interactifs)
üö® System & Alerts - Sant√© syst√®me et alertes critiques
üìä Metrics & Logs - Stats et logs d√©taill√©s

üí° Astuce : Mute les topics dont tu n'as pas besoin en ce moment.
   Tu peux toujours les consulter manuellement plus tard !

Commandes utiles : /status, /journal, /confiance

Pr√™t √† commencer ? üöÄ
```

**Suggestion Mary (Analyst)** : Ce message aide Antonio √† comprendre **o√π regarder pour quoi** sans lire 50 pages de doc.

### 11.8 Impact sur Stories Existantes

#### Story 1.5 (Observability & Trust Layer)

**Modifications requises** :

1. `services/alerting/telegram_notifier.py` doit impl√©menter routing multi-topics
   - Remplacer envoi sur canal unique par routage selon `route_event_to_topic()`
   - Tester tous les cas de routage (unit tests)

2. Bot Telegram doit g√©rer messages entrants (bidirectionnel)
   - Listener sur topic Chat & Proactive pour commandes Antonio
   - R√©ponses dans le m√™me thread_id

3. Inline buttons pour validations dans Actions & Validations topic
   - Boutons Approve/Reject doivent fonctionner en context topic

**Estimation impact** : +4h dev + 2h tests

#### Story 2.5 (Heartbeat Engine)

**Modifications requises** :

- Heartbeat checks s'affichent dans **Chat & Proactive topic**
- Conversations initi√©es par heartbeat continuent dans m√™me fil (pr√©servation contexte)

**Estimation impact** : Aucun (architecture d√©j√† compatible)

#### Nouvelle Story 1.6 : Telegram Topics Implementation

**√Ä cr√©er** (voir section 11.9 ci-dessous)

### 11.9 Story 1.6 - Telegram Topics Implementation (Outline)

**Epic** : Telegram Topics Architecture

**Stories** :

1. **Story 1.6.1 : Documentation** (cette section + guides)
   - Section 11 architecture-addendum ‚úÖ (ce document)
   - Guide technique setup (`docs/telegram-topics-setup.md`)
   - User guide (`docs/telegram-user-guide.md`)
   - Mise √† jour CLAUDE.md
   - Mise √† jour DECISION_LOG.md

2. **Story 1.6.2 : Supergroup Setup** (manuel Antonio)
   - Cr√©er supergroup Telegram
   - Activer topics feature
   - Cr√©er 5 topics nomm√©s
   - Ajouter bot Friday (admin rights)
   - Extraire thread IDs via script

3. **Story 1.6.3 : Bot Routing Implementation**
   - Config `telegram.yaml` avec topics
   - Router logic par module/priorit√©/type
   - Bidirectional message handling (Chat & Proactive)
   - Unit tests routing

4. **Story 1.6.4 : Inline Buttons & Commands**
   - Inline buttons pour trust=propose validations
   - Command handlers (`/status`, `/journal`, etc.)
   - Onboarding message au first join
   - Integration tests

5. **Story 1.6.5 : E2E Testing & Deployment**
   - Test E2E tous topics
   - Validation routing correct (100 events simul√©s)
   - Performance test (100 events/min)
   - D√©ploiement production

**Dur√©e totale estim√©e** : 17-18h (2-3 jours dev)

**D√©pendances** : Story 1.6.1 DONE avant 1.6.3 start.

### 11.10 D√©cisions Diff√©r√©es (v2.0 post-MVP)

Les fonctionnalit√©s suivantes sont **hors scope v1.0** :

- **Notifications push s√©lectives par topic** : Config granulaire par topic (son custom, vibration pattern)
- **Message formatting avanc√©** : Embeds, rich media, graphs inline
- **Analytics par topic** : Taux de lecture, temps de r√©ponse, engagement
- **Telegram Mini Apps int√©gration** : Dashboard interactif in-app
- **Multi-langue topics** : Noms topics localis√©s (FR/EN selon config)

**R√©√©valuation** : 3 mois apr√®s Story 1.6 d√©ploy√©e (feedback Antonio).

---

**Cree le** : 2026-02-05
**Mis a jour** : 2026-02-09 (D19 : pgvector remplace Qdrant Day 1, D17 : remplacement Mistral par Claude Sonnet 4.5, nettoyage references Ollama LLM)
**Version** : 1.4
