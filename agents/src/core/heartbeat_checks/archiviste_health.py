"""
Heartbeat Check - Sant√© Pipeline Archiviste

Check p√©riodique sant√© composants archiviste :
- Surya OCR responsive
- Watchdog observer actif (Story 3.5)
- Pipeline traitement documents fonctionnel

Priority: HIGH (alerte si pipeline bloqu√© >24h)
Quiet hours: Non (syst√®me critique)
"""

from datetime import datetime, timedelta
from typing import Any, Dict, Optional

import asyncpg
import httpx
import structlog
from agents.src.core.heartbeat_models import CheckPriority, CheckResult
from redis.asyncio import Redis

logger = structlog.get_logger(__name__)


# ============================================================================
# CHECK FUNCTION
# ============================================================================


async def check_archiviste_health(
    context: Dict[str, Any],
    db_pool: Optional[asyncpg.Pool] = None,
    redis_client: Optional[Redis] = None,
) -> CheckResult:
    """
    Check Heartbeat : Sant√© pipeline archiviste

    V√©rifie 3 composants critiques :
    1. Surya OCR responsive (simple health ping)
    2. Watchdog observer actif (Redis heartbeat)
    3. Pipeline documents fonctionnel (derni√®re action <24h)

    Args:
        context: Contexte Heartbeat (time, hour, etc.)
        db_pool: Pool PostgreSQL (optionnel, cr√©√© si None)
        redis_client: Redis client (optionnel, cr√©√© si None)

    Returns:
        CheckResult avec notify=True si anomalie d√©tect√©e

    Epic 3 - Archiviste Health Monitoring
    """
    pool_created = False
    redis_created = False
    issues = []

    try:
        # 1. V√©rifier Surya OCR responsive
        ocr_issue = await _check_surya_ocr()
        if ocr_issue:
            issues.append(ocr_issue)

        # 2. V√©rifier Watchdog observer actif (Redis heartbeat)
        if redis_client is None:
            import os

            redis_url = os.getenv("REDIS_URL")
            if redis_url:
                redis_client = Redis.from_url(redis_url)
                redis_created = True

        if redis_client:
            watchdog_issue = await _check_watchdog_observer(redis_client)
            if watchdog_issue:
                issues.append(watchdog_issue)

        # 3. V√©rifier pipeline documents fonctionnel (derni√®re action <24h)
        if db_pool is None:
            import os

            database_url = os.getenv("DATABASE_URL")
            if not database_url:
                logger.error("DATABASE_URL envvar manquante")
                return CheckResult(notify=False, error="DATABASE_URL envvar manquante")

            db_pool = await asyncpg.create_pool(database_url)
            pool_created = True

        pipeline_issue = await _check_pipeline_activity(db_pool)
        if pipeline_issue:
            issues.append(pipeline_issue)

        # 4. Formater r√©sultat
        if not issues:
            logger.debug("heartbeat_check_archiviste_ok")
            return CheckResult(notify=False, message="")

        # Notifier si anomalies d√©tect√©es
        logger.warning(
            "heartbeat_check_archiviste_issues_found", issue_count=len(issues), issues=issues
        )

        message = _format_health_notification(issues, context)

        return CheckResult(
            notify=True,
            message=message,
            action="check_archiviste",
            payload={"issues": issues, "severity": "high" if len(issues) >= 2 else "medium"},
        )

    except Exception as e:
        logger.error("heartbeat_check_archiviste_error", error=str(e), exc_info=True)
        return CheckResult(notify=False, error=str(e))
    finally:
        # Cleanup resources si cr√©√©s localement
        if pool_created and db_pool:
            await db_pool.close()
        if redis_created and redis_client:
            await redis_client.close()


# ============================================================================
# HELPERS - Health Checks
# ============================================================================


async def _check_surya_ocr() -> Optional[str]:
    """
    V√©rifie si Surya OCR responsive via simple health ping

    Returns:
        None si OK, message erreur sinon

    Story 3.1 - OCR renommage intelligent
    """
    import os

    surya_url = os.getenv("SURYA_OCR_URL", "http://localhost:8765")
    health_endpoint = f"{surya_url}/health"

    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(health_endpoint)

            if response.status_code == 200:
                logger.debug("surya_ocr_health_ok", url=surya_url)
                return None

            logger.warning(
                "surya_ocr_health_bad_status",
                url=surya_url,
                status_code=response.status_code,
            )
            return f"Surya OCR unhealthy (HTTP {response.status_code})"

    except httpx.TimeoutException:
        logger.warning("surya_ocr_health_timeout", url=surya_url)
        return "Surya OCR timeout (>5s)"
    except Exception as e:
        logger.warning("surya_ocr_health_error", url=surya_url, error=str(e))
        return f"Surya OCR inaccessible ({str(e)[:50]})"


async def _check_watchdog_observer(redis_client: Redis) -> Optional[str]:
    """
    V√©rifie si Watchdog observer actif via Redis heartbeat

    Le watchdog observer publie un heartbeat toutes les 60s dans Redis
    key: watchdog:heartbeat, TTL: 120s

    Returns:
        None si OK, message erreur sinon

    Story 3.5 - D√©tection nouveaux fichiers
    """
    try:
        heartbeat_key = "watchdog:heartbeat"
        last_heartbeat = await redis_client.get(heartbeat_key)

        if last_heartbeat:
            logger.debug("watchdog_observer_active")
            return None

        # Pas de heartbeat d√©tect√©
        logger.warning("watchdog_observer_no_heartbeat")
        return "Watchdog observer inactif (pas de heartbeat Redis)"

    except Exception as e:
        logger.warning("watchdog_observer_check_error", error=str(e))
        return f"Watchdog observer check failed ({str(e)[:50]})"


async def _check_pipeline_activity(db_pool: asyncpg.Pool) -> Optional[str]:
    """
    V√©rifie activit√© pipeline documents via derni√®re action archiviste

    R√®gle : Si zone transit non-vide ET aucun document trait√© depuis >24h
    ‚Üí Alerte pipeline bloqu√©

    Returns:
        None si OK, message erreur sinon

    Epic 3 - Pipeline archiviste
    """
    try:
        # 1. V√©rifier derni√®re action archiviste dans core.action_receipts
        async with db_pool.acquire() as conn:
            last_action = await conn.fetchrow(
                """
                SELECT created_at
                FROM core.action_receipts
                WHERE module = 'archiviste'
                ORDER BY created_at DESC
                LIMIT 1
                """
            )

            if not last_action:
                logger.debug("archiviste_pipeline_no_history")
                return None  # Pas d'historique = syst√®me neuf, OK

            last_action_time = last_action["created_at"]
            time_since_last = datetime.now() - last_action_time

            # 2. Si derni√®re action <24h, pipeline OK
            if time_since_last < timedelta(hours=24):
                logger.debug(
                    "archiviste_pipeline_active",
                    last_action_hours_ago=time_since_last.total_seconds() / 3600,
                )
                return None

            # 3. Derni√®re action >24h : V√©rifier si zone transit vide
            # (Si transit vide = pas de documents √† traiter = OK)
            import os

            transit_path = os.getenv("TRANSIT_ATTACHMENTS_PATH", "/var/friday/transit/attachments")

            # Note : Cette v√©rification n√©cessite acc√®s filesystem VPS
            # Day 1 : Skip filesystem check, alerte bas√©e uniquement sur last_action >24h
            # TODO : Impl√©menter check filesystem transit via agent local ou SSH

            logger.warning(
                "archiviste_pipeline_inactive",
                last_action_hours_ago=time_since_last.total_seconds() / 3600,
            )

            hours_ago = int(time_since_last.total_seconds() / 3600)
            return f"Pipeline archiviste inactif (derni√®re action il y a {hours_ago}h)"

    except Exception as e:
        logger.warning("archiviste_pipeline_check_error", error=str(e))
        return f"Pipeline check failed ({str(e)[:50]})"


# ============================================================================
# HELPERS - Notification Formatting
# ============================================================================


def _format_health_notification(issues: list[str], context: Dict[str, Any]) -> str:
    """
    Formate message notification Telegram sant√© archiviste

    Format :
    üö® Probl√®mes d√©tect√©s pipeline archiviste

    ‚ùå Surya OCR unhealthy (HTTP 503)
    ‚ùå Watchdog observer inactif
    ‚ùå Pipeline inactif (derni√®re action 36h)

    V√©rifiez services via /status

    Args:
        issues: Liste messages erreurs d√©tect√©es
        context: Contexte Heartbeat

    Returns:
        Message HTML format√© pour Telegram
    """
    count = len(issues)

    lines = [
        f"üö® <b>{count} probl√®me{'s' if count > 1 else ''} d√©tect√©{'s' if count > 1 else ''} pipeline archiviste</b>",
        "",
    ]

    # Lister probl√®mes
    for issue in issues:
        lines.append(f"‚ùå {issue}")

    lines.append("")
    lines.append("<i>V√©rifiez services via /status</i>")

    return "\n".join(lines)


# ============================================================================
# METADATA (pour enregistrement Heartbeat Engine)
# ============================================================================

CHECK_METADATA = {
    "name": "archiviste_health",
    "priority": CheckPriority.HIGH,
    "description": "V√©rifie sant√© pipeline archiviste (OCR, Watchdog, activit√©)",
    "function": check_archiviste_health,
    "epic": "3",
    "phase": 2,  # Heartbeat Phase 2 (checks sant√© syst√®me)
}
