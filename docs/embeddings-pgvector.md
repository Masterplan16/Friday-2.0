# Friday 2.0 - Embeddings & Recherche S√©mantique

**Date**: 2026-02-11
**Story**: 6.2 - Embeddings pgvector
**Provider**: Voyage AI voyage-4-large (1024 dims, multilingual)
**Vectorstore**: PostgreSQL 16 + pgvector v0.8.1 (HNSW index)

---

## Architecture

```mermaid
sequenceDiagram
    participant Content as Email/Document
    participant Presidio
    participant Voyage as Voyage AI
    participant PG as PostgreSQL + pgvector
    participant Search as Recherche

    Content->>Presidio: Texte brut
    Presidio-->>Content: Texte anonymis√©
    Content->>Voyage: Texte anonymis√©
    Voyage-->>Content: Embedding [1024 floats]
    Content->>PG: INSERT knowledge.embeddings
    PG-->>Content: Stock√©

    Search->>Presidio: Query utilisateur
    Presidio-->>Search: Query anonymis√©e
    Search->>Voyage: Query ‚Üí embedding
    Voyage-->>Search: Query embedding
    Search->>PG: SELECT ... ORDER BY <=> LIMIT 10
    PG-->>Search: Top 10 r√©sultats
```

---

## Configuration

### Variables d'environnement

```bash
# .env
VOYAGE_API_KEY=vo-xxxxxxxxxxxxx
EMBEDDING_PROVIDER=voyage
EMBEDDING_DIMENSIONS=1024
```

### Voyage AI Setup

1. Cr√©er compte : https://www.voyageai.com/
2. G√©n√©rer API key depuis dashboard
3. Ajouter dans `.env` (chiffr√© avec SOPS pour production)

**Pricing** : ~$0.06/1M tokens (batch API)
**Budget estim√©** : ~10-15 EUR/mois pour Friday (100k embeddings/mois)

---

## Utilisation

### G√©n√©ration embeddings automatique

**Email** :
```python
# Automatique lors de populate_email_graph()
await populate_email_graph(email_data, memorystore)
# ‚Üí Embedding g√©n√©r√© + stock√© dans knowledge.embeddings
```

**Document** :
```python
from agents.src.agents.archiviste.embedding_generator import generate_document_embeddings

count = await generate_document_embeddings(
    document_node_id="doc_123",
    text="Contenu document OCR...",
    vectorstore=vectorstore,
)
# ‚Üí Retourne nombre d'embeddings g√©n√©r√©s (chunking si >10k chars)
```

### Recherche s√©mantique

**API Gateway** :
```bash
POST /api/v1/search/semantic
{
    "query": "facture plombier",
    "top_k": 10,
    "filters": {"node_type": "document"}
}
```

**Telegram** :
```
/search facture plombier
/search SGLT2 diab√®te
```

**Python** :
```python
from agents.src.adapters.vectorstore import get_vectorstore_adapter

vectorstore = await get_vectorstore_adapter()

# Recherche
results = await vectorstore.search(
    query_embedding=query_emb,
    top_k=10,
    filters={"node_type": "document", "date_range": {"start": "2026-01-01"}}
)

for result in results:
    print(f"{result.node_id}: {result.similarity:.2f}")
```

---

## Sp√©cifications Techniques

### pgvector HNSW Index

```sql
CREATE INDEX idx_embeddings_hnsw ON knowledge.embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**Param√®tres** :
- `m=16` : Connexions par n≈ìud (trade-off recall/RAM)
- `ef_construction=64` : Effort build index (trade-off recall/speed)

**Performance** :
- <100ms pour 100k vecteurs (HNSW ANN)
- <500ms pour 300k vecteurs
- R√©-√©valuation Qdrant si >300k vecteurs OU latence >100ms

### Chunking Documents

**Param√®tres** :
- `CHUNK_SIZE = 2000` chars
- `CHUNK_OVERLAP = 200` chars

**Comportement** :
- Document <10k chars ‚Üí 1 embedding
- Document >10k chars ‚Üí N embeddings (1 par chunk)
- Recherche : `MAX(similarity)` par node_id

---

## S√©curit√© RGPD

‚ö†Ô∏è **CRITIQUE** : Anonymisation Presidio OBLIGATOIRE avant Voyage AI

**Pipeline** :
1. Texte brut (peut contenir PII)
2. ‚Üí Presidio anonymise
3. ‚Üí Texte anonymis√© envoy√© √† Voyage AI
4. ‚Üí AUCUNE PII en clair au cloud

**Mapping √©ph√©m√®re** : Redis TTL 5min pour d√©-anonymisation r√©sultats

---

## Monitoring

### Budget API

```bash
# Commande Telegram
/budget

# Output:
üí∞ Budget API F√©vrier 2026
üìä LLM Claude: 42.30 EUR
üîç Embeddings Voyage: 8.70 EUR
üìà Total: 51.00 EUR / 73.00 EUR
```

### Alertes

- **>20 EUR embeddings/mois** ‚Üí Alerte Telegram System
- **>80% budget total** ‚Üí Alerte + email Mainteneur

---

## Troubleshooting

**Erreur : Voyage API down**
- Retry automatique 3x avec backoff
- Email cr√©√© quand m√™me (embedding manquant)
- Job nightly retentera g√©n√©ration

**Latence >100ms**
- V√©rifier nombre vecteurs : `SELECT COUNT(*) FROM knowledge.embeddings;`
- Si >300k ‚Üí Consid√©rer migration Qdrant

**Taille index HNSW >10 Go**
- Monitoring : `SELECT pg_total_relation_size('knowledge.idx_embeddings_hnsw');`
- Ajuster param√®tres `m` ou `ef_construction`

---

## Migration Provider

Swap Voyage AI ‚Üí autre provider :

1. Cr√©er adapter dans `agents/src/adapters/vectorstore.py`
2. Ajouter dans factory `get_vectorstore_adapter()`
3. Changer `EMBEDDING_PROVIDER` dans `.env`

**Alternatives** :
- OpenAI : `text-embedding-3-large` (3072 dims, $0.13/1M)
- Cohere : `embed-multilingual-v3.0` (1024 dims, $0.10/1M)
- Ollama local : `nomic-embed-text` (768 dims, gratuit)

---

**Impl√©ment√© dans Story 6.2** ‚úÖ
