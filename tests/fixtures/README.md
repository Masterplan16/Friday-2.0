# Tests Fixtures - Datasets de validation IA

**Objectif** : CrÃ©er des datasets manuels pour valider la qualitÃ© des agents IA de Friday 2.0.

**StratÃ©gie** : Pyramide de tests â€” 80% unit (mocks), 15% integ (datasets), 5% E2E.

---

## ğŸ“Š **Datasets requis**

### **1. PII Samples (Anonymisation RGPD)** âœ… CRITIQUE

**Fichier** : `tests/fixtures/pii_samples.json`

**Objectif** : Valider que Presidio anonymise TOUTES les donnÃ©es sensibles avant LLM cloud.

**Contenu** : 20 exemples variÃ©s de PII (Personally Identifiable Information)

| Type d'entitÃ© | Exemples | QuantitÃ© min |
|---------------|----------|--------------|
| PERSON | "Jean Dupont", "Dr. Marie Martin" | 5 |
| DATE_TIME | "15/03/1980", "2026-02-05" | 3 |
| LOCATION | "123 rue de la Paix 75001 Paris" | 3 |
| PHONE_NUMBER | "0612345678", "+33 6 12 34 56 78" | 3 |
| EMAIL_ADDRESS | "jean.dupont@example.com" | 3 |
| IBAN_CODE | "FR76 1234 5678 9012 3456 7890 123" | 2 |
| MEDICAL_INFO | "DiabÃ¨te type 2", "Traitement SGLT2" | 3 |

**Format JSON** :
```json
{
  "samples": [
    {
      "id": "pii_001",
      "input": "Le patient Jean Dupont, nÃ© le 15/03/1980...",
      "entities": ["PERSON", "DATE_TIME", "LOCATION", ...],
      "sensitive_values": ["Jean Dupont", "15/03/1980", ...]
    }
  ]
}
```

**CrÃ©ation** :
- **Responsable** : Mainteneur (fournit 20 exemples rÃ©els anonymisÃ©s)
- **Quand** : Avant Story 1.5 (Trust Layer dÃ©pend de Presidio)
- **DurÃ©e estimÃ©e** : 1-2h (collecte + formatting)

**Test associÃ©** : `tests/integration/test_anonymization_pipeline.py`

---

### **2. Email Classification (Module Moteur Vie)** âœ… CRITIQUE

**Fichier** : `tests/fixtures/email_classification_dataset.json`

**Objectif** : Valider accuracy >85% de la classification emails.

**Contenu** : 50 emails reprÃ©sentatifs couvrant toutes les catÃ©gories

| CatÃ©gorie | QuantitÃ© min | Exemples sujets |
|-----------|--------------|-----------------|
| **medical** | 8 | "RÃ©sultats ECG patient", "RÃ©union staff mÃ©dical" |
| **finance** | 8 | "Facture URSSAF", "RelevÃ© bancaire SELARL" |
| **thesis** | 8 | "Version 3 introduction thÃ¨se Julie" |
| **legal** | 5 | "Bail cabinet Ã©chÃ©ance", "Contrat rÃ©vision" |
| **personal** | 5 | "Invitation anniversaire", "Relance plombier" |
| **professional** | 8 | "ConfÃ©rence SFMU 2026", "Demande expertise" |
| **spam** | 5 | "Gagnez 1000â‚¬", "Augmentez vos followers" |
| **ambiguous** | 3 | "RÃ©union demain" (flou) |

**Format JSON** :
```json
{
  "emails": [
    {
      "id": "email_001",
      "subject": "RÃ©sultats ECG patient Dupont",
      "text": "Bonjour, voici les rÃ©sultats ECG...",
      "expected_category": "medical",
      "expected_priority": "medium",
      "min_confidence": 0.80
    }
  ]
}
```

**CrÃ©ation** :
- **MÃ©thode** : Export 50 emails reprÃ©sentatifs depuis Thunderbird
- **Responsable** : Mainteneur (sÃ©lection + anonymisation)
- **Quand** : Avant Story 2 (module Email)
- **DurÃ©e estimÃ©e** : 2-3h (export + anonymisation + labelling)

**Test associÃ©** : `tests/integration/test_email_classification_quality.py`

---

### **3. Document Archiviste (Renommage + Classification)** âœ… HAUTE

**Fichier** : `tests/fixtures/archiviste_dataset/`

**Objectif** : Valider renommage intelligent + classification documents.

**Contenu** : 30 documents PDF/images variÃ©s

| Type document | QuantitÃ© | Exemples |
|---------------|----------|----------|
| Factures | 10 | Plombier, Ã©lectricitÃ©, matÃ©riel bureau |
| Contrats | 5 | Bail, assurance, prestation |
| Articles mÃ©dicaux | 5 | PDF PubMed, HAS |
| Scans divers | 5 | Carte grise, permis, diplÃ´me |
| Photos | 5 | Photos famille, vacances |

**Format** :
```
tests/fixtures/archiviste_dataset/
â”œâ”€â”€ factures/
â”‚   â”œâ”€â”€ scan_001.pdf (â†’ attendu: 2026-02-01_Facture_Plomberie_Dupont_250e.pdf)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ contrats/
â”‚   â””â”€â”€ ...
â””â”€â”€ metadata.json (expected_filename, expected_category, expected_doc_type)
```

**CrÃ©ation** :
- **MÃ©thode** : Collecter 30 documents existants + anonymiser
- **Responsable** : Mainteneur
- **Quand** : Avant Story 3 (module Archiviste)
- **DurÃ©e estimÃ©e** : 2-3h

**Test associÃ©** : `tests/integration/test_archiviste_quality.py`

---

### **4. Finance Anomalies** âœ… HAUTE

**Fichier** : `tests/fixtures/finance_anomalies.csv`

**Objectif** : Valider dÃ©tection anomalies financiÃ¨res (precision >90%).

**Contenu** : 100 transactions (90 normales, 10 anormales)

| Type anomalie | QuantitÃ© | Exemples |
|---------------|----------|----------|
| Facture en double | 3 | MÃªme montant, mÃªme vendeur, dates proches |
| DÃ©pense inhabituelle | 3 | Montant 3Ã— supÃ©rieur Ã  moyenne catÃ©gorie |
| Seuil trÃ©sorerie | 2 | Compte <500â‚¬ (alerte) |
| Abonnement non utilisÃ© | 2 | DerniÃ¨re utilisation >6 mois |

**Format CSV** :
```csv
date,amount,vendor,category,account,is_anomaly,anomaly_type
2026-01-15,250.50,"Plomberie Dupont",maintenance,SELARL,false,
2026-01-16,250.50,"Plomberie Dupont",maintenance,SELARL,true,duplicate
...
```

**CrÃ©ation** :
- **MÃ©thode** : Export CSV bancaires SELARL + ajout anomalies synthÃ©tiques
- **Responsable** : Mainteneur (fournit CSV rÃ©el + indique anomalies connues)
- **Quand** : Avant Story 6 (module Suivi Financier)
- **DurÃ©e estimÃ©e** : 1h

**Test associÃ©** : `tests/integration/test_finance_anomalies_quality.py`

---

### **5. Tuteur ThÃ¨se (DÃ©tection erreurs mÃ©thodologiques)** âœ… MOYENNE

**Fichier** : `tests/fixtures/thesis_extracts/`

**Objectif** : Valider dÃ©tection erreurs mÃ©thodologiques (F1-score >70%).

**Contenu** : 20 extraits de thÃ¨ses (500-1000 mots) avec erreurs annotÃ©es

| Type erreur | QuantitÃ© | Exemples |
|-------------|----------|----------|
| Structure IMRAD | 5 | MÃ©thode avant introduction, etc. |
| MÃ©thodologie | 5 | Ã‰chantillon non reprÃ©sentatif, biais sÃ©lection |
| Statistiques | 5 | Test inappropriÃ©, p-value mal interprÃ©tÃ©e |
| RÃ©daction | 5 | Phrases passives, jargon non dÃ©fini |

**Format** :
```
tests/fixtures/thesis_extracts/
â”œâ”€â”€ extract_001_structure_error.md
â”‚   (annotations: <!-- ERREUR: Introduction manquante -->)
â”œâ”€â”€ extract_002_methodology_error.md
â””â”€â”€ metadata.json (expected_errors: ["structure", "methodology", ...])
```

**CrÃ©ation** :
- **MÃ©thode** : Extraits anonymisÃ©s de thÃ¨ses rÃ©elles
- **Responsable** : Mainteneur (fournit 20 extraits + annote erreurs)
- **Quand** : Avant Story 7 (module Tuteur ThÃ¨se)
- **DurÃ©e estimÃ©e** : 3-4h

**Test associÃ©** : `tests/integration/test_thesis_tutor_quality.py`

---

## ğŸ“… **Planning de crÃ©ation**

| Dataset | PrioritÃ© | Deadline | Effort | Responsable |
|---------|----------|----------|--------|-------------|
| **PII Samples** | P0 | Avant Story 1.5 | 1-2h | Mainteneur |
| **Email Classification** | P0 | Avant Story 2 | 2-3h | Mainteneur |
| **Document Archiviste** | P1 | Avant Story 3 | 2-3h | Mainteneur |
| **Finance Anomalies** | P1 | Avant Story 6 | 1h | Mainteneur |
| **Tuteur ThÃ¨se** | P2 | Avant Story 7 | 3-4h | Mainteneur |

**Total effort estimÃ©** : 9-13h de travail Mainteneur (collecte + anonymisation + labelling)

---

## ğŸ› ï¸ **Outils de crÃ©ation**

### **Export emails Thunderbird**

```bash
# 1. SÃ©lectionner 50 emails reprÃ©sentatifs dans Thunderbird
# 2. Clic droit â†’ "Sauvegarder comme" â†’ Format EML
# 3. Script Python pour convertir EML â†’ JSON

python scripts/convert_eml_to_dataset.py \
  --input emails_export/*.eml \
  --output tests/fixtures/email_classification_dataset.json
```

### **Anonymisation batch**

```python
# scripts/anonymize_dataset.py
# Utilise Presidio pour anonymiser batch de documents/emails

python scripts/anonymize_dataset.py \
  --input tests/fixtures/raw/ \
  --output tests/fixtures/email_classification_dataset.json
```

---

## âœ… **Validation des datasets**

Chaque dataset doit passer ces checks avant commit :

1. **Format valide** : JSON parsable, schÃ©ma Pydantic respectÃ©
2. **PII nettoyÃ©es** : Aucune donnÃ©e sensible rÃ©elle (vÃ©rif manuelle)
3. **QuantitÃ© suffisante** : Minimum requis atteint
4. **DiversitÃ©** : Toutes les catÃ©gories/cas reprÃ©sentÃ©s
5. **Labelling cohÃ©rent** : expected_* fields corrects

**Script de validation** :

```bash
python scripts/validate_datasets.py
# VÃ©rifie tous les datasets dans tests/fixtures/
```

---

## ğŸ“ **Notes**

- **Datasets = fichiers gitignored** si contiennent des donnÃ©es sensibles (mÃªme anonymisÃ©es)
- **Alternative** : Datasets synthÃ©tiques gÃ©nÃ©rÃ©s par LLM (qualitÃ© infÃ©rieure mais rapide)
- **Maintenance** : Enrichir datasets quand Friday fait une erreur en prod (feedback loop)

---

**CrÃ©Ã© le** : 2026-02-05
**Version** : 1.0.0
