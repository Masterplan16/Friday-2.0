# Tests Fixtures - Datasets de validation IA

**Objectif** : Cr√©er des datasets manuels pour valider la qualit√© des agents IA de Friday 2.0.

**Strat√©gie** : Pyramide de tests ‚Äî 80% unit (mocks), 15% integ (datasets), 5% E2E.

---

## üìä **Datasets requis**

### **1. PII Samples (Anonymisation RGPD)** ‚úÖ CRITIQUE

**Fichier** : `tests/fixtures/pii_samples.json`

**Objectif** : Valider que Presidio anonymise TOUTES les donn√©es sensibles avant LLM cloud.

**Contenu** : 20 exemples vari√©s de PII (Personally Identifiable Information)

| Type d'entit√© | Exemples | Quantit√© min |
|---------------|----------|--------------|
| PERSON | "Jean Dupont", "Dr. Marie Martin" | 5 |
| DATE_TIME | "15/03/1980", "2026-02-05" | 3 |
| LOCATION | "123 rue de la Paix 75001 Paris" | 3 |
| PHONE_NUMBER | "0612345678", "+33 6 12 34 56 78" | 3 |
| EMAIL_ADDRESS | "jean.dupont@example.com" | 3 |
| IBAN_CODE | "FR76 1234 5678 9012 3456 7890 123" | 2 |
| MEDICAL_INFO | "Diab√®te type 2", "Traitement SGLT2" | 3 |

**Format JSON** :
```json
{
  "samples": [
    {
      "id": "pii_001",
      "input": "Le patient Jean Dupont, n√© le 15/03/1980...",
      "entities": ["PERSON", "DATE_TIME", "LOCATION", ...],
      "sensitive_values": ["Jean Dupont", "15/03/1980", ...]
    }
  ]
}
```

**Cr√©ation** :
- **Responsable** : Mainteneur (fournit 20 exemples r√©els anonymis√©s)
- **Quand** : Avant Story 1.5 (Trust Layer d√©pend de Presidio)
- **Dur√©e estim√©e** : 1-2h (collecte + formatting)

**Test associ√©** : `tests/integration/test_anonymization_pipeline.py`

---

### **2. Email Classification (Module Moteur Vie)** ‚úÖ CRITIQUE

**Fichier** : `tests/fixtures/email_classification_dataset.json`

**Objectif** : Valider accuracy >85% de la classification emails.

**Contenu** : 50 emails repr√©sentatifs couvrant toutes les cat√©gories

| Cat√©gorie | Quantit√© min | Exemples sujets |
|-----------|--------------|-----------------|
| **medical** | 8 | "R√©sultats ECG patient", "R√©union staff m√©dical" |
| **finance** | 8 | "Facture URSSAF", "Relev√© bancaire SELARL" |
| **thesis** | 8 | "Version 3 introduction th√®se Julie" |
| **legal** | 5 | "Bail cabinet √©ch√©ance", "Contrat r√©vision" |
| **personal** | 5 | "Invitation anniversaire", "Relance plombier" |
| **professional** | 8 | "Conf√©rence SFMU 2026", "Demande expertise" |
| **spam** | 5 | "Gagnez 1000‚Ç¨", "Augmentez vos followers" |
| **ambiguous** | 3 | "R√©union demain" (flou) |

**Format JSON** :
```json
{
  "emails": [
    {
      "id": "email_001",
      "subject": "R√©sultats ECG patient Dupont",
      "text": "Bonjour, voici les r√©sultats ECG...",
      "expected_category": "medical",
      "expected_priority": "medium",
      "min_confidence": 0.80
    }
  ]
}
```

**Cr√©ation** :
- **M√©thode** : Export 50 emails repr√©sentatifs depuis Thunderbird
- **Responsable** : Mainteneur (s√©lection + anonymisation)
- **Quand** : Avant Story 2 (module Email)
- **Dur√©e estim√©e** : 2-3h (export + anonymisation + labelling)

**Test associ√©** : `tests/integration/test_email_classification_quality.py`

---

### **3. Document Archiviste (Renommage + Classification)** ‚úÖ HAUTE

**Fichier** : `tests/fixtures/archiviste_dataset/`

**Objectif** : Valider renommage intelligent + classification documents.

**Contenu** : 30 documents PDF/images vari√©s

| Type document | Quantit√© | Exemples |
|---------------|----------|----------|
| Factures | 10 | Plombier, √©lectricit√©, mat√©riel bureau |
| Contrats | 5 | Bail, assurance, prestation |
| Articles m√©dicaux | 5 | PDF PubMed, HAS |
| Scans divers | 5 | Carte grise, permis, dipl√¥me |
| Photos | 5 | Photos famille, vacances |

**Format** :
```
tests/fixtures/archiviste_dataset/
‚îú‚îÄ‚îÄ factures/
‚îÇ   ‚îú‚îÄ‚îÄ scan_001.pdf (‚Üí attendu: 2026-02-01_Facture_Plomberie_Dupont_250e.pdf)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ contrats/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metadata.json (expected_filename, expected_category, expected_doc_type)
```

**Cr√©ation** :
- **M√©thode** : Collecter 30 documents existants + anonymiser
- **Responsable** : Antonio
- **Quand** : Avant Story 3 (module Archiviste)
- **Dur√©e estim√©e** : 2-3h

**Test associ√©** : `tests/integration/test_archiviste_quality.py`

---

### **4. Finance Anomalies** ‚úÖ HAUTE

**Fichier** : `tests/fixtures/finance_anomalies.csv`

**Objectif** : Valider d√©tection anomalies financi√®res (precision >90%).

**Contenu** : 100 transactions (90 normales, 10 anormales)

| Type anomalie | Quantit√© | Exemples |
|---------------|----------|----------|
| Facture en double | 3 | M√™me montant, m√™me vendeur, dates proches |
| D√©pense inhabituelle | 3 | Montant 3√ó sup√©rieur √† moyenne cat√©gorie |
| Seuil tr√©sorerie | 2 | Compte <500‚Ç¨ (alerte) |
| Abonnement non utilis√© | 2 | Derni√®re utilisation >6 mois |

**Format CSV** :
```csv
date,amount,vendor,category,account,is_anomaly,anomaly_type
2026-01-15,250.50,"Plomberie Dupont",maintenance,SELARL,false,
2026-01-16,250.50,"Plomberie Dupont",maintenance,SELARL,true,duplicate
...
```

**Cr√©ation** :
- **M√©thode** : Export CSV bancaires SELARL + ajout anomalies synth√©tiques
- **Responsable** : Mainteneur (fournit CSV r√©el + indique anomalies connues)
- **Quand** : Avant Story 6 (module Suivi Financier)
- **Dur√©e estim√©e** : 1h

**Test associ√©** : `tests/integration/test_finance_anomalies_quality.py`

---

### **5. Tuteur Th√®se (D√©tection erreurs m√©thodologiques)** ‚úÖ MOYENNE

**Fichier** : `tests/fixtures/thesis_extracts/`

**Objectif** : Valider d√©tection erreurs m√©thodologiques (F1-score >70%).

**Contenu** : 20 extraits de th√®ses (500-1000 mots) avec erreurs annot√©es

| Type erreur | Quantit√© | Exemples |
|-------------|----------|----------|
| Structure IMRAD | 5 | M√©thode avant introduction, etc. |
| M√©thodologie | 5 | √âchantillon non repr√©sentatif, biais s√©lection |
| Statistiques | 5 | Test inappropri√©, p-value mal interpr√©t√©e |
| R√©daction | 5 | Phrases passives, jargon non d√©fini |

**Format** :
```
tests/fixtures/thesis_extracts/
‚îú‚îÄ‚îÄ extract_001_structure_error.md
‚îÇ   (annotations: <!-- ERREUR: Introduction manquante -->)
‚îú‚îÄ‚îÄ extract_002_methodology_error.md
‚îî‚îÄ‚îÄ metadata.json (expected_errors: ["structure", "methodology", ...])
```

**Cr√©ation** :
- **M√©thode** : Extraits anonymis√©s de th√®ses r√©elles
- **Responsable** : Mainteneur (fournit 20 extraits + annote erreurs)
- **Quand** : Avant Story 7 (module Tuteur Th√®se)
- **Dur√©e estim√©e** : 3-4h

**Test associ√©** : `tests/integration/test_thesis_tutor_quality.py`

---

## üìÖ **Planning de cr√©ation**

| Dataset | Priorit√© | Deadline | Effort | Responsable |
|---------|----------|----------|--------|-------------|
| **PII Samples** | P0 | Avant Story 1.5 | 1-2h | Antonio |
| **Email Classification** | P0 | Avant Story 2 | 2-3h | Antonio |
| **Document Archiviste** | P1 | Avant Story 3 | 2-3h | Antonio |
| **Finance Anomalies** | P1 | Avant Story 6 | 1h | Antonio |
| **Tuteur Th√®se** | P2 | Avant Story 7 | 3-4h | Antonio |

**Total effort estim√©** : 9-13h de travail Mainteneur (collecte + anonymisation + labelling)

---

## üõ†Ô∏è **Outils de cr√©ation**

### **Export emails Thunderbird**

```bash
# 1. S√©lectionner 50 emails repr√©sentatifs dans Thunderbird
# 2. Clic droit ‚Üí "Sauvegarder comme" ‚Üí Format EML
# 3. Script Python pour convertir EML ‚Üí JSON

python scripts/convert_eml_to_dataset.py \
  --input emails_export/*.eml \
  --output tests/fixtures/email_classification_dataset.json
```

### **Anonymisation batch**

```python
# scripts/anonymize_dataset.py
# Utilise Presidio pour anonymiser batch de documents/emails

python scripts/anonymize_dataset.py \
  --input tests/fixtures/raw/ \
  --output tests/fixtures/email_classification_dataset.json
```

---

## ‚úÖ **Validation des datasets**

Chaque dataset doit passer ces checks avant commit :

1. **Format valide** : JSON parsable, sch√©ma Pydantic respect√©
2. **PII nettoy√©es** : Aucune donn√©e sensible r√©elle (v√©rif manuelle)
3. **Quantit√© suffisante** : Minimum requis atteint
4. **Diversit√©** : Toutes les cat√©gories/cas repr√©sent√©s
5. **Labelling coh√©rent** : expected_* fields corrects

**Script de validation** :

```bash
python scripts/validate_datasets.py
# V√©rifie tous les datasets dans tests/fixtures/
```

---

## üìù **Notes**

- **Datasets = fichiers gitignored** si contiennent des donn√©es sensibles (m√™me anonymis√©es)
- **Alternative** : Datasets synth√©tiques g√©n√©r√©s par LLM (qualit√© inf√©rieure mais rapide)
- **Maintenance** : Enrichir datasets quand Friday fait une erreur en prod (feedback loop)

---

**Cr√©√© le** : 2026-02-05
**Version** : 1.0.0
